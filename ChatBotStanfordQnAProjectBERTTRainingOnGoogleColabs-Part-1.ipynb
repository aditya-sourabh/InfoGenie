{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## This part of the project was done in local PC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Loading the dev and train data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "e_-PP64oEb4B",
        "outputId": "2d54ddbb-c9f2-4fae-8fdf-d5fa85372df9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample from dev-v1.1.json: {'answers': [{'answer_start': 177, 'text': 'Denver Broncos'}, {'answer_start': 177, 'text': 'Denver Broncos'}, {'answer_start': 177, 'text': 'Denver Broncos'}], 'question': 'Which NFL team represented the AFC at Super Bowl 50?', 'id': '56be4db0acb8001400a502ec'}\n",
            "Sample from train-v1.1.json: {'answers': [{'answer_start': 515, 'text': 'Saint Bernadette Soubirous'}], 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'id': '5733be284776f41900661182'}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "# File paths\n",
        "dev_file_path = r'D:\\Rajesh\\Rajesh\\Personal\\AISanDiego\\520-NLP\\Project\\OriginalData\\StanfordQA\\dev-v1.1.json'\n",
        "train_file_path = r'D:\\Rajesh\\Rajesh\\Personal\\AISanDiego\\520-NLP\\Project\\OriginalData\\StanfordQA\\train-v1.1.json'\n",
        "\n",
        "# Load dev data\n",
        "with open(dev_file_path, 'r', encoding='utf-8') as dev_file:\n",
        "    dev_squad_data = json.load(dev_file)\n",
        "\n",
        "# Load train data\n",
        "with open(train_file_path, 'r', encoding='utf-8') as train_file:\n",
        "    train_squad_data = json.load(train_file)\n",
        "\n",
        "# Print the loaded data (optional)\n",
        "print(f\"Sample from dev-v1.1.json: {dev_squad_data['data'][0]['paragraphs'][0]['qas'][0]}\")\n",
        "print(f\"Sample from train-v1.1.json: {train_squad_data['data'][0]['paragraphs'][0]['qas'][0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqyGTNvcPGg4",
        "outputId": "17c89707-60b1-4be5-ba68-6f4bd06ad563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample from extracted training data: ('Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'Saint Bernadette Soubirous', 515)\n",
            "Sample from extracted dev data: ('Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.', 'Which NFL team represented the AFC at Super Bowl 50?', 'Denver Broncos', 177)\n"
          ]
        }
      ],
      "source": [
        "# Define a function to extract question-answer pairs from the dataset.\n",
        "def extract_qna_pairs_for_bert(squad_data):\n",
        "    qna_pairs = []\n",
        "    for article in squad_data['data']:\n",
        "        for paragraph in article['paragraphs']:\n",
        "            context = paragraph['context']\n",
        "            for qas in paragraph['qas']:\n",
        "                question = qas['question']\n",
        "                if qas.get('is_impossible', False):\n",
        "                    answer = \"I don't know.\"\n",
        "                    answer_start = -1  # No answer available\n",
        "                else:\n",
        "                    # Take the first answer\n",
        "                    answer = qas['answers'][0]['text'] if qas['answers'] else \"No answer available.\"\n",
        "                    answer_start = qas['answers'][0]['answer_start']\n",
        "                qna_pairs.append((context, question, answer, answer_start))\n",
        "    return qna_pairs\n",
        "\n",
        "# Step 5: Extract question-answer pairs from both train and dev datasets\n",
        "qna_pairs_train = extract_qna_pairs_for_bert(train_squad_data)\n",
        "qna_pairs_dev = extract_qna_pairs_for_bert(dev_squad_data)\n",
        "\n",
        "# Displaying a sample of the extracted data\n",
        "print(f\"Sample from extracted training data: {qna_pairs_train[0]}\")\n",
        "print(f\"Sample from extracted dev data: {qna_pairs_dev[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihsGIL9437b1",
        "outputId": "1df2e487-6a41-4a39-adbf-fe5a73771e4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned sample from training data: ('architecturally, the school has a catholic character. atop the main building\\'s gold dome is a golden statue of the virgin mary. immediately in front of the main building and facing it, is a copper statue of christ with arms upraised with the legend \"venite ad me omnes\". next to the main building is the basilica of the sacred heart. immediately behind the basilica is the grotto, a marian place of prayer and reflection. it is a replica of the grotto at lourdes, france where the virgin mary reputedly appeared to saint bernadette soubirous in 1858. at the end of the main drive (and in a direct line that connects through 3 statues and the gold dome), is a simple, modern stone statue of mary.', 'to whom did the virgin mary allegedly appear in 1858 in lourdes france?', 'saint bernadette soubirous', 515)\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Function to clean text (removes unnecessary whitespace, lowercasing, etc.)\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Lowercase the text (since we're using an uncased model)\n",
        "    text = text.replace('\\n', ' ').replace('\\r', ' ')  # Remove newline and carriage returns\n",
        "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
        "    text = text.strip()  # Remove leading and trailing whitespace\n",
        "    return text\n",
        "\n",
        "# Apply cleaning to the extracted question-answer pairs before tokenization\n",
        "def clean_qna_pairs(qna_pairs):\n",
        "    cleaned_qna_pairs = []\n",
        "    for context, question, answer, answer_start in qna_pairs:\n",
        "        cleaned_context = clean_text(context)\n",
        "        cleaned_question = clean_text(question)\n",
        "        cleaned_answer = clean_text(answer)\n",
        "        cleaned_qna_pairs.append((cleaned_context, cleaned_question, cleaned_answer, answer_start))\n",
        "    return cleaned_qna_pairs\n",
        "\n",
        "# Step 6 (Revised): Clean the extracted train and dev data before tokenization\n",
        "cleaned_qna_pairs_train = clean_qna_pairs(qna_pairs_train)\n",
        "cleaned_qna_pairs_dev = clean_qna_pairs(qna_pairs_dev)\n",
        "\n",
        "# Displaying a sample of cleaned data\n",
        "print(f\"Cleaned sample from training data: {cleaned_qna_pairs_train[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJyK1L_VDgmr",
        "outputId": "32792b9a-96ff-477f-f980-10875cef9208"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample tokenized data from training set: {'input_ids': [101, 2000, 3183, 2106, 1996, 6261, 2984, 9382, 3711, 1999, 8517, 1999, 10223, 26371, 2605, 1029, 102, 6549, 2135, 1010, 1996, 2082, 2038, 1037, 3234, 2839, 1012, 10234, 1996, 2364, 2311, 1005, 1055, 2751, 8514, 2003, 1037, 3585, 6231, 1997, 1996, 6261, 2984, 1012, 3202, 1999, 2392, 1997, 1996, 2364, 2311, 1998, 5307, 2009, 1010, 2003, 1037, 6967, 6231, 1997, 4828, 2007, 2608, 2039, 14995, 6924, 2007, 1996, 5722, 1000, 2310, 3490, 2618, 4748, 2033, 18168, 5267, 1000, 1012, 2279, 2000, 1996, 2364, 2311, 2003, 1996, 13546, 1997, 1996, 6730, 2540, 1012, 3202, 2369, 1996, 13546, 2003, 1996, 24665, 23052, 1010, 1037, 14042, 2173, 1997, 7083, 1998, 9185, 1012, 2009, 2003, 1037, 15059, 1997, 1996, 24665, 23052, 2012, 10223, 26371, 1010, 2605, 2073, 1996, 6261, 2984, 22353, 2135, 2596, 2000, 3002, 16595, 9648, 4674, 2061, 12083, 9711, 2271, 1999, 8517, 1012, 2012, 1996, 2203, 1997, 1996, 2364, 3298, 1006, 1998, 1999, 1037, 3622, 2240, 2008, 8539, 2083, 1017, 11342, 1998, 1996, 2751, 8514, 1007, 1010, 2003, 1037, 3722, 1010, 2715, 2962, 6231, 1997, 2984, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'start_position': 130, 'end_position': 137}\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "# Load the pre-trained BERT fast tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Function to tokenize the cleaned question-answer pairs and find the token positions of the answer\n",
        "def tokenize_qna_pairs(qna_pairs, tokenizer, max_length=128):\n",
        "    tokenized_data = []\n",
        "\n",
        "    for context, question, answer, answer_start in qna_pairs:\n",
        "        # Tokenize the question and context together\n",
        "        encoding = tokenizer.encode_plus(\n",
        "            question,\n",
        "            context,\n",
        "            max_length=max_length,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_offsets_mapping=True,  # Now this will work with the fast tokenizer\n",
        "            return_token_type_ids=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = encoding['input_ids'].squeeze().tolist()  # Convert to list\n",
        "        attention_mask = encoding['attention_mask'].squeeze().tolist()  # Convert to list\n",
        "        token_type_ids = encoding['token_type_ids'].squeeze().tolist()  # Convert to list\n",
        "        offset_mapping = encoding['offset_mapping'].squeeze().tolist()  # Convert to list\n",
        "\n",
        "        # Initialize start and end positions of the answer\n",
        "        start_position = 0\n",
        "        end_position = 0\n",
        "\n",
        "        # Find the token positions corresponding to the answer if it's not unanswerable\n",
        "        if answer_start != -1:\n",
        "            for idx, (start, end) in enumerate(offset_mapping):\n",
        "                if start <= answer_start < end:\n",
        "                    start_position = idx\n",
        "                if start < answer_start + len(answer) <= end:\n",
        "                    end_position = idx\n",
        "                    break\n",
        "\n",
        "        # Append tokenized data\n",
        "        tokenized_data.append({\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'token_type_ids': token_type_ids,\n",
        "            'start_position': start_position,\n",
        "            'end_position': end_position\n",
        "        })\n",
        "\n",
        "    return tokenized_data\n",
        "\n",
        "# Tokenize the cleaned question-answer pairs\n",
        "tokenized_train = tokenize_qna_pairs(cleaned_qna_pairs_train, tokenizer)\n",
        "tokenized_dev = tokenize_qna_pairs(cleaned_qna_pairs_dev, tokenizer)\n",
        "\n",
        "# Display a sample of the tokenized data\n",
        "print(f\"Sample tokenized data from training set: {tokenized_train[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN42T83c6sgA",
        "outputId": "c0d013d4-e5d2-48a9-8cc2-12b608470630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pre-processed data saved successfully!\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "# Save tokenized data to files using pickle\n",
        "with open('tokenized_train.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenized_train, f)\n",
        "\n",
        "with open('tokenized_dev.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenized_dev, f)\n",
        "\n",
        "print(\"Pre-processed data saved successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The files tokenized_train.pkl and tokenized_dev.pkl were uploaded to the Gooogle Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### This part of the project was done in Google Colabs Pro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrrno-vT66KC",
        "outputId": "333d2635-3145-4dbf-eba2-9405856dea68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Tokenized data loaded successfully from Google Drive.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the load path from your Google Drive\n",
        "load_path_train = '/content/drive/My Drive/SQuAD_datasets/tokenized_train.pkl'\n",
        "load_path_dev = '/content/drive/My Drive/SQuAD_datasets/tokenized_dev.pkl'\n",
        "\n",
        "# Load the tokenized training and dev datasets\n",
        "with open(load_path_train, 'rb') as f:\n",
        "    tokenized_train = pickle.load(f)\n",
        "\n",
        "with open(load_path_dev, 'rb') as f:\n",
        "    tokenized_dev = pickle.load(f)\n",
        "\n",
        "print(\"Tokenized data loaded successfully from Google Drive.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0IGQEXw7e0u",
        "outputId": "6c2c7875-4287-439e-91de-7314e837cd74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([  101,  2000,  3183,  2106,  1996,  6261,  2984,  9382,  3711,  1999,\n",
            "         8517,  1999, 10223, 26371,  2605,  1029,   102,  6549,  2135,  1010,\n",
            "         1996,  2082,  2038,  1037,  3234,  2839,  1012, 10234,  1996,  2364,\n",
            "         2311,  1005,  1055,  2751,  8514,  2003,  1037,  3585,  6231,  1997,\n",
            "         1996,  6261,  2984,  1012,  3202,  1999,  2392,  1997,  1996,  2364,\n",
            "         2311,  1998,  5307,  2009,  1010,  2003,  1037,  6967,  6231,  1997,\n",
            "         4828,  2007,  2608,  2039, 14995,  6924,  2007,  1996,  5722,  1000,\n",
            "         2310,  3490,  2618,  4748,  2033, 18168,  5267,  1000,  1012,  2279,\n",
            "         2000,  1996,  2364,  2311,  2003,  1996, 13546,  1997,  1996,  6730,\n",
            "         2540,  1012,  3202,  2369,  1996, 13546,  2003,  1996, 24665, 23052,\n",
            "         1010,  1037, 14042,  2173,  1997,  7083,  1998,  9185,  1012,  2009,\n",
            "         2003,  1037, 15059,  1997,  1996, 24665, 23052,  2012, 10223, 26371,\n",
            "         1010,  2605,  2073,  1996,  6261,  2984, 22353,  2135,  2596,  2000,\n",
            "         3002, 16595,  9648,  4674,  2061, 12083,  9711,  2271,  1999,  8517,\n",
            "         1012,  2012,  1996,  2203,  1997,  1996,  2364,  3298,  1006,  1998,\n",
            "         1999,  1037,  3622,  2240,  2008,  8539,  2083,  1017, 11342,  1998,\n",
            "         1996,  2751,  8514,  1007,  1010,  2003,  1037,  3722,  1010,  2715,\n",
            "         2962,  6231,  1997,  2984,  1012,   102,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'start_positions': tensor(130), 'end_positions': tensor(137)}\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# Custom Dataset class for Question Answering\n",
        "class QADataset(Dataset):\n",
        "    def __init__(self, tokenized_data):\n",
        "        self.tokenized_data = tokenized_data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Return the input IDs, attention mask, token type IDs, start and end positions as a dictionary\n",
        "        item = self.tokenized_data[idx]\n",
        "        return {\n",
        "            'input_ids': torch.tensor(item['input_ids']),\n",
        "            'attention_mask': torch.tensor(item['attention_mask']),\n",
        "            'token_type_ids': torch.tensor(item['token_type_ids']),\n",
        "            'start_positions': torch.tensor(item['start_position']),\n",
        "            'end_positions': torch.tensor(item['end_position'])\n",
        "        }\n",
        "\n",
        "# Step 2: Create Dataset objects for train and dev sets\n",
        "train_dataset = QADataset(tokenized_train)\n",
        "dev_dataset = QADataset(tokenized_dev)\n",
        "\n",
        "# Display a sample from the training dataset\n",
        "print(train_dataset[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1uw-8oY7p6x",
        "outputId": "5b5d2672-31e7-41d0-a287-5dcebd5661de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[ 101, 2054, 2001,  ...,    0,    0,    0],\n",
            "        [ 101, 2029, 2028,  ...,    0,    0,    0],\n",
            "        [ 101, 2055, 2129,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 101, 2043, 2064,  ...,    0,    0,    0],\n",
            "        [ 101, 2054, 4654,  ...,    0,    0,    0],\n",
            "        [ 101, 2006, 2029,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 0, 0, 0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]]), 'start_positions': tensor([ 58,  10,  23,  62,   7,  85, 109,  55]), 'end_positions': tensor([ 59,  11,  23,  63,  11,  91, 113,  56])}\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create DataLoaders for the training and dev datasets\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=4, shuffle=False)\n",
        "\n",
        "# Display a batch of data (for demonstration purposes)\n",
        "for batch in train_loader:\n",
        "    print(batch)\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8b50b02e4de24a8bb150576ab725fd38",
            "3271d85a4e1b463d907f1ed429695224",
            "278a824bca1745f5b235d916cd62c677",
            "3f9ab103b36b4b8097a8caea323c589b",
            "2ac43049cd264c8ea1b034bbe26223d7",
            "2ff7180bcb1b44c8ba5e1f10e63bfeef",
            "cdef2072ebd5467b9f80cd7f74639dc9",
            "d1348a6856f54c55974f1bcf94fdeb54",
            "3b1f2795378646b8b051a163a0f3299c",
            "75b039342e57402eb33b2cc4de0ee415",
            "3ceb5298c51745fdb1393163029cdcd9"
          ]
        },
        "id": "0coMvsCZ7q-o",
        "outputId": "afa5ddbb-6a81-4eb3-e712-86fe5f6995a9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b50b02e4de24a8bb150576ab725fd38",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   1%|          | 101/10950 [00:18<30:32,  5.92it/s, loss=2.99]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 100): 4.231133337020874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   2%|▏         | 201/10950 [00:35<30:16,  5.92it/s, loss=2.77]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 200): 2.912179082632065\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   3%|▎         | 301/10950 [00:52<29:56,  5.93it/s, loss=1.79]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 300): 2.369250613451004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   4%|▎         | 401/10950 [01:09<29:41,  5.92it/s, loss=2.83]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 400): 2.2766072434186935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   5%|▍         | 501/10950 [01:26<29:23,  5.92it/s, loss=2.83]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 500): 2.1141357856988905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   5%|▌         | 601/10950 [01:43<29:08,  5.92it/s, loss=1.38]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 600): 1.9195109552145004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   6%|▋         | 701/10950 [02:00<28:54,  5.91it/s, loss=1.79]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 700): 1.8866946029663085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   7%|▋         | 801/10950 [02:16<28:43,  5.89it/s, loss=1.47]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 800): 1.9747071641683578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   8%|▊         | 901/10950 [02:33<28:30,  5.88it/s, loss=2.02]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 900): 1.8879171204566956\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   9%|▉         | 1001/10950 [02:50<28:11,  5.88it/s, loss=2.11]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1000): 1.7568739259243011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  10%|█         | 1101/10950 [03:07<27:47,  5.90it/s, loss=1.07]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1100): 1.828685192465782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  11%|█         | 1201/10950 [03:24<27:25,  5.93it/s, loss=2.01]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1200): 1.6802969819307327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  12%|█▏        | 1301/10950 [03:41<27:09,  5.92it/s, loss=1.59]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1300): 1.66411246240139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  13%|█▎        | 1401/10950 [03:58<26:52,  5.92it/s, loss=1.31]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1400): 1.6818364343047143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  14%|█▎        | 1501/10950 [04:15<26:42,  5.90it/s, loss=1.28]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1500): 1.6593033689260483\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  15%|█▍        | 1601/10950 [04:32<26:15,  5.93it/s, loss=0.978]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1600): 1.865857258439064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  16%|█▌        | 1701/10950 [04:49<26:10,  5.89it/s, loss=1.39]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1700): 1.7516514253616333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  16%|█▋        | 1801/10950 [05:06<25:43,  5.93it/s, loss=1.26]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1800): 1.807899168729782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  17%|█▋        | 1901/10950 [05:23<25:32,  5.90it/s, loss=0.981]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1900): 1.685603232383728\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  18%|█▊        | 2001/10950 [05:39<25:10,  5.92it/s, loss=1.79]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2000): 1.6249693983793259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  19%|█▉        | 2101/10950 [05:56<24:55,  5.92it/s, loss=1.09]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2100): 1.5806910580396651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  20%|██        | 2201/10950 [06:13<24:37,  5.92it/s, loss=1.26]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2200): 1.5625329154729843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  21%|██        | 2301/10950 [06:30<24:27,  5.90it/s, loss=1.98]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2300): 1.5627302926778794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  22%|██▏       | 2401/10950 [06:47<24:14,  5.88it/s, loss=0.55]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2400): 1.6001496088504792\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  23%|██▎       | 2501/10950 [07:04<23:54,  5.89it/s, loss=2.07]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2500): 1.5792154026031495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  24%|██▍       | 2601/10950 [07:21<23:30,  5.92it/s, loss=1.75]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2600): 1.5203211778402328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  25%|██▍       | 2701/10950 [07:38<23:22,  5.88it/s, loss=0.943]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2700): 1.6044514656066895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  26%|██▌       | 2801/10950 [07:55<23:02,  5.89it/s, loss=1.41]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2800): 1.473583105802536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  26%|██▋       | 2901/10950 [08:12<22:45,  5.90it/s, loss=1.54]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2900): 1.563006012737751\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  27%|██▋       | 3001/10950 [08:29<22:31,  5.88it/s, loss=1.61]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3000): 1.5067556113004685\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  28%|██▊       | 3101/10950 [08:46<22:14,  5.88it/s, loss=1.14]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3100): 1.5565893906354904\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  29%|██▉       | 3201/10950 [09:03<21:57,  5.88it/s, loss=0.937]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3200): 1.450670051574707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  30%|███       | 3301/10950 [09:20<21:35,  5.91it/s, loss=2.02]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3300): 1.458396223783493\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  31%|███       | 3401/10950 [09:37<21:18,  5.91it/s, loss=1.58]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3400): 1.5069265288114548\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  32%|███▏      | 3501/10950 [09:54<20:55,  5.93it/s, loss=1.26]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3500): 1.4965335160493851\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  33%|███▎      | 3601/10950 [10:11<20:41,  5.92it/s, loss=0.989]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3600): 1.444773304462433\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  34%|███▍      | 3701/10950 [10:28<20:23,  5.92it/s, loss=1.32]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3700): 1.4417149555683135\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  35%|███▍      | 3801/10950 [10:45<20:10,  5.91it/s, loss=0.832]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3800): 1.4794166743755341\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  36%|███▌      | 3901/10950 [11:01<19:55,  5.90it/s, loss=1.58]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3900): 1.4225502301752568\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  37%|███▋      | 4001/10950 [11:18<19:46,  5.85it/s, loss=1.52]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4000): 1.5182668191194535\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  37%|███▋      | 4101/10950 [11:35<19:24,  5.88it/s, loss=0.91]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4100): 1.4659151381254196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  38%|███▊      | 4201/10950 [11:52<19:05,  5.89it/s, loss=1.24]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4200): 1.4658956590294838\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  39%|███▉      | 4301/10950 [12:09<18:42,  5.92it/s, loss=1.75]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4300): 1.4499608474969863\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  40%|████      | 4401/10950 [12:26<18:33,  5.88it/s, loss=1.75]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4400): 1.442686133980751\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  41%|████      | 4501/10950 [12:43<18:07,  5.93it/s, loss=0.758]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4500): 1.3406383687257766\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  42%|████▏     | 4601/10950 [13:00<17:54,  5.91it/s, loss=1.4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4600): 1.4766210317611694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  43%|████▎     | 4701/10950 [13:17<17:46,  5.86it/s, loss=2.17]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4700): 1.3942710494995116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  44%|████▍     | 4801/10950 [13:34<17:22,  5.90it/s, loss=1.2]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4800): 1.4430437353253365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  45%|████▍     | 4901/10950 [13:51<17:08,  5.88it/s, loss=1.12]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4900): 1.4823771661520004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  46%|████▌     | 5001/10950 [14:08<16:41,  5.94it/s, loss=2.07]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5000): 1.348692879974842\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  47%|████▋     | 5101/10950 [14:25<16:32,  5.89it/s, loss=1.54]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5100): 1.4798288017511367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  47%|████▋     | 5201/10950 [14:42<16:17,  5.88it/s, loss=1]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5200): 1.3364314818382264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  48%|████▊     | 5301/10950 [14:59<15:58,  5.89it/s, loss=1.36]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5300): 1.3706478190422058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  49%|████▉     | 5401/10950 [15:16<15:44,  5.88it/s, loss=0.703]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5400): 1.3737234944105148\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  50%|█████     | 5501/10950 [15:33<15:23,  5.90it/s, loss=0.823]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5500): 1.4413296872377395\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  51%|█████     | 5601/10950 [15:50<15:06,  5.90it/s, loss=1.64]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5600): 1.4723910468816757\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  52%|█████▏    | 5701/10950 [16:07<14:51,  5.89it/s, loss=1.57]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5700): 1.4395577186346054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  53%|█████▎    | 5801/10950 [16:24<14:32,  5.90it/s, loss=0.545]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5800): 1.315556971281767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  54%|█████▍    | 5901/10950 [16:41<14:17,  5.89it/s, loss=1.35]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5900): 1.368814223408699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  55%|█████▍    | 6001/10950 [16:58<14:00,  5.89it/s, loss=0.581]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6000): 1.3510711264610291\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  56%|█████▌    | 6101/10950 [17:15<13:41,  5.91it/s, loss=1.13]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6100): 1.30744107991457\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  57%|█████▋    | 6201/10950 [17:32<13:24,  5.91it/s, loss=1.43]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6200): 1.312435777783394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  58%|█████▊    | 6301/10950 [17:49<13:07,  5.90it/s, loss=1.57]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6300): 1.3882810223102569\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  58%|█████▊    | 6401/10950 [18:06<12:53,  5.88it/s, loss=1.89]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6400): 1.383493773341179\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  59%|█████▉    | 6501/10950 [18:23<12:33,  5.90it/s, loss=1.03]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6500): 1.422709275186062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  60%|██████    | 6601/10950 [18:40<12:16,  5.90it/s, loss=1.49]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6600): 1.2815143385529517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  61%|██████    | 6701/10950 [18:57<12:01,  5.89it/s, loss=0.74]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6700): 1.3922441419959068\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  62%|██████▏   | 6801/10950 [19:14<11:44,  5.89it/s, loss=0.674]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6800): 1.3549937349557877\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  63%|██████▎   | 6901/10950 [19:31<11:29,  5.87it/s, loss=1.33]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6900): 1.4413858470320702\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  64%|██████▍   | 7001/10950 [19:48<11:08,  5.91it/s, loss=2.13]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7000): 1.4023393937945365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  65%|██████▍   | 7101/10950 [20:05<10:51,  5.91it/s, loss=1.15]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7100): 1.3116497644782066\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  66%|██████▌   | 7201/10950 [20:22<10:38,  5.87it/s, loss=0.728]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7200): 1.3666022819280625\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  67%|██████▋   | 7301/10950 [20:39<10:19,  5.89it/s, loss=0.954]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7300): 1.3402511224150657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  68%|██████▊   | 7401/10950 [20:56<10:04,  5.87it/s, loss=1.26]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7400): 1.2899995079636575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  69%|██████▊   | 7501/10950 [21:13<09:44,  5.90it/s, loss=0.456]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7500): 1.3808028200268745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  69%|██████▉   | 7601/10950 [21:30<09:26,  5.91it/s, loss=1.81]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7600): 1.3409116458892822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  70%|███████   | 7701/10950 [21:47<09:12,  5.88it/s, loss=1.3]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7700): 1.3005077937245368\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  71%|███████   | 7801/10950 [22:04<08:53,  5.90it/s, loss=1.65]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7800): 1.2866896617412567\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  72%|███████▏  | 7901/10950 [22:21<08:38,  5.88it/s, loss=1.33]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7900): 1.3470619440078735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  73%|███████▎  | 8001/10950 [22:38<08:20,  5.89it/s, loss=2.54]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8000): 1.2840837585926055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  74%|███████▍  | 8101/10950 [22:54<08:01,  5.91it/s, loss=0.528]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8100): 1.378340622484684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  75%|███████▍  | 8201/10950 [23:11<07:47,  5.88it/s, loss=0.73]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8200): 1.3115431779623032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  76%|███████▌  | 8301/10950 [23:28<07:30,  5.88it/s, loss=0.879]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8300): 1.2989031603932382\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  77%|███████▋  | 8401/10950 [23:45<07:14,  5.87it/s, loss=1.37]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8400): 1.4059040869772435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  78%|███████▊  | 8501/10950 [24:02<06:56,  5.88it/s, loss=1.18]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8500): 1.2994653677940369\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  79%|███████▊  | 8601/10950 [24:19<06:39,  5.89it/s, loss=0.84]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8600): 1.1525496944785119\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  79%|███████▉  | 8701/10950 [24:36<06:22,  5.88it/s, loss=2.5]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8700): 1.248946667611599\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  80%|████████  | 8801/10950 [24:54<06:06,  5.86it/s, loss=0.905]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8800): 1.4420182833075523\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  81%|████████▏ | 8901/10950 [25:11<05:49,  5.87it/s, loss=1.71]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8900): 1.3348596784472466\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  82%|████████▏ | 9001/10950 [25:28<05:30,  5.89it/s, loss=0.862]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9000): 1.350067713856697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  83%|████████▎ | 9101/10950 [25:45<05:14,  5.87it/s, loss=1.25]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9100): 1.2513131320476532\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  84%|████████▍ | 9201/10950 [26:02<04:58,  5.86it/s, loss=0.85]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9200): 1.2617910397052765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  85%|████████▍ | 9301/10950 [26:19<04:40,  5.87it/s, loss=2.91]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9300): 1.2623129391670227\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  86%|████████▌ | 9401/10950 [26:36<04:23,  5.87it/s, loss=0.587]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9400): 1.303351265490055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  87%|████████▋ | 9501/10950 [26:53<04:07,  5.86it/s, loss=0.926]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9500): 1.3340770304203033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  88%|████████▊ | 9601/10950 [27:10<03:48,  5.90it/s, loss=1.81]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9600): 1.2101370260119437\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  89%|████████▊ | 9701/10950 [27:27<03:32,  5.87it/s, loss=1.3]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9700): 1.1865194511413575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  90%|████████▉ | 9801/10950 [27:44<03:15,  5.87it/s, loss=1.81]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9800): 1.2753180342912673\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  90%|█████████ | 9901/10950 [28:01<02:58,  5.86it/s, loss=1.64]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9900): 1.4082538765668868\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  91%|█████████▏| 10001/10950 [28:18<02:41,  5.89it/s, loss=1.27]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10000): 1.2964188036322595\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  92%|█████████▏| 10101/10950 [28:35<02:23,  5.92it/s, loss=1.64]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10100): 1.2265375584363938\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  93%|█████████▎| 10201/10950 [28:52<02:06,  5.92it/s, loss=1.67]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10200): 1.3156971007585525\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  94%|█████████▍| 10301/10950 [29:09<01:50,  5.89it/s, loss=1.7]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10300): 1.2922768852114677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  95%|█████████▍| 10401/10950 [29:26<01:33,  5.88it/s, loss=1.9]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10400): 1.2621716755628585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  96%|█████████▌| 10501/10950 [29:43<01:15,  5.91it/s, loss=1.96]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10500): 1.2992165726423264\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  97%|█████████▋| 10601/10950 [30:00<00:59,  5.89it/s, loss=1.35]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10600): 1.260861890912056\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  98%|█████████▊| 10701/10950 [30:17<00:42,  5.91it/s, loss=0.431]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10700): 1.195641074180603\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  99%|█████████▊| 10801/10950 [30:34<00:25,  5.89it/s, loss=0.895]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10800): 1.3104521614313125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|█████████▉| 10901/10950 [30:51<00:08,  5.87it/s, loss=0.994]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10900): 1.2341378499567508\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 10950/10950 [30:59<00:00,  5.89it/s, loss=0.924]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Training Loss for Epoch 1: 1.4985162891590431\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 1322/1322 [01:11<00:00, 18.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss for Epoch 1: 1.2199324916896048\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   1%|          | 101/10950 [00:17<30:43,  5.89it/s, loss=0.331]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 100): 0.924407060444355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   2%|▏         | 201/10950 [00:34<30:18,  5.91it/s, loss=0.698]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 200): 0.9300924651324749\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   3%|▎         | 301/10950 [00:51<30:03,  5.91it/s, loss=1.31]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 300): 1.0771314196288586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   4%|▎         | 401/10950 [01:08<30:03,  5.85it/s, loss=0.435]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 400): 0.8663683373481035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   5%|▍         | 501/10950 [01:25<29:26,  5.91it/s, loss=0.47]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 500): 0.8846160148084163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   5%|▌         | 601/10950 [01:42<29:27,  5.85it/s, loss=1.27]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 600): 0.8258506479859352\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   6%|▋         | 701/10950 [01:59<28:54,  5.91it/s, loss=1.32]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 700): 1.0181281113624572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   7%|▋         | 801/10950 [02:16<28:42,  5.89it/s, loss=0.649]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 800): 0.9742316399514676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   8%|▊         | 901/10950 [02:33<28:36,  5.85it/s, loss=1.12]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 900): 0.997510738670826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   9%|▉         | 1001/10950 [02:50<28:09,  5.89it/s, loss=1.13]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1000): 0.8843038403987884\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  10%|█         | 1101/10950 [03:07<28:03,  5.85it/s, loss=0.41]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1100): 0.9147082915902138\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  11%|█         | 1201/10950 [03:24<27:26,  5.92it/s, loss=0.757]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1200): 0.9290052103996277\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  12%|█▏        | 1301/10950 [03:41<27:15,  5.90it/s, loss=1.29]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1300): 0.932818411141634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  13%|█▎        | 1401/10950 [03:58<27:07,  5.87it/s, loss=0.788]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1400): 0.9416036546230316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  14%|█▎        | 1501/10950 [04:15<26:45,  5.89it/s, loss=1.37]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1500): 0.9263731473684311\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  15%|█▍        | 1601/10950 [04:32<26:37,  5.85it/s, loss=0.855]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1600): 0.9530100095272064\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  16%|█▌        | 1701/10950 [04:49<26:10,  5.89it/s, loss=0.827]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1700): 0.9010267536342144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  16%|█▋        | 1801/10950 [05:06<25:58,  5.87it/s, loss=0.679]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1800): 0.9904400339722633\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  17%|█▋        | 1901/10950 [05:23<25:38,  5.88it/s, loss=1.49]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1900): 0.8697358265519142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  18%|█▊        | 2001/10950 [05:40<25:26,  5.86it/s, loss=0.682]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2000): 0.8760607869923115\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  19%|█▉        | 2101/10950 [05:57<25:06,  5.87it/s, loss=1.17]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2100): 0.8952296856790781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  20%|██        | 2201/10950 [06:14<24:47,  5.88it/s, loss=2.21]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2200): 0.8714557604491711\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  21%|██        | 2301/10950 [06:31<24:26,  5.90it/s, loss=1.34]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2300): 1.0198830777406693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  22%|██▏       | 2401/10950 [06:48<24:14,  5.88it/s, loss=0.266]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2400): 0.9741590777039528\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  23%|██▎       | 2501/10950 [07:05<23:59,  5.87it/s, loss=0.402]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2500): 0.8874775977432727\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  24%|██▍       | 2601/10950 [07:22<23:38,  5.88it/s, loss=1.18]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2600): 0.8920603650808334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  25%|██▍       | 2701/10950 [07:39<23:20,  5.89it/s, loss=0.434]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2700): 0.9733079394698143\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  26%|██▌       | 2801/10950 [07:56<23:11,  5.86it/s, loss=1.43]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2800): 0.9265006364881992\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  26%|██▋       | 2901/10950 [08:13<22:47,  5.89it/s, loss=0.901]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2900): 0.9636178581416607\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  27%|██▋       | 3001/10950 [08:30<22:32,  5.88it/s, loss=1.17]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3000): 0.9585382680594922\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  28%|██▊       | 3101/10950 [08:47<22:12,  5.89it/s, loss=1.76]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3100): 0.9868783676624298\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  29%|██▉       | 3201/10950 [09:04<21:57,  5.88it/s, loss=0.656]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3200): 0.8899102374911309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  30%|███       | 3301/10950 [09:21<21:46,  5.85it/s, loss=0.921]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3300): 0.9112424510717392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  31%|███       | 3401/10950 [09:38<21:20,  5.89it/s, loss=1.14]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3400): 0.9876384434103965\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  32%|███▏      | 3501/10950 [09:55<21:05,  5.89it/s, loss=0.273]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3500): 0.9353512638807296\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  33%|███▎      | 3601/10950 [10:12<20:50,  5.88it/s, loss=1.32]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3600): 0.8639615586400032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  34%|███▍      | 3701/10950 [10:29<20:31,  5.89it/s, loss=2.36]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3700): 0.967567281126976\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  35%|███▍      | 3801/10950 [10:46<20:20,  5.86it/s, loss=0.693]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3800): 1.0572121921181679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  36%|███▌      | 3901/10950 [11:03<19:55,  5.90it/s, loss=0.55]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3900): 0.9252089658379554\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  37%|███▋      | 4001/10950 [11:20<19:37,  5.90it/s, loss=0.11]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4000): 0.8814530879259109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  37%|███▋      | 4101/10950 [11:37<19:25,  5.88it/s, loss=0.628]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4100): 0.8632175302505494\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  38%|███▊      | 4201/10950 [11:54<19:18,  5.82it/s, loss=1.24]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4200): 0.9268594269454479\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  39%|███▉      | 4301/10950 [12:11<18:53,  5.87it/s, loss=0.805]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4300): 0.8883069033920765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  40%|████      | 4401/10950 [12:28<18:31,  5.89it/s, loss=0.583]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4400): 0.8651677818596363\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  41%|████      | 4501/10950 [12:45<18:15,  5.89it/s, loss=1.28]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4500): 0.9326132363080979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  42%|████▏     | 4601/10950 [13:02<18:03,  5.86it/s, loss=0.52]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4600): 0.9268405148386956\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  43%|████▎     | 4701/10950 [13:19<17:42,  5.88it/s, loss=1.05]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4700): 0.9471060232818127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  44%|████▍     | 4801/10950 [13:36<17:28,  5.86it/s, loss=0.651]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4800): 0.9296570785343647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  45%|████▍     | 4901/10950 [13:53<17:10,  5.87it/s, loss=1.88]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4900): 0.856698967218399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  46%|████▌     | 5001/10950 [14:11<16:56,  5.85it/s, loss=0.548]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5000): 0.9553475099802017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  47%|████▋     | 5101/10950 [14:28<16:37,  5.87it/s, loss=1.59]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5100): 0.8517435038089752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  47%|████▋     | 5201/10950 [14:45<16:20,  5.86it/s, loss=1.44]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5200): 0.9332230095565319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  48%|████▊     | 5301/10950 [15:02<16:04,  5.85it/s, loss=0.382]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5300): 0.9234274254739284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  49%|████▉     | 5401/10950 [15:19<15:43,  5.88it/s, loss=0.549]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5400): 0.9259538571536541\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  50%|█████     | 5501/10950 [15:36<15:26,  5.88it/s, loss=2.3]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5500): 0.9424075277149677\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  51%|█████     | 5601/10950 [15:53<15:13,  5.86it/s, loss=0.554]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5600): 0.9622169329226017\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  52%|█████▏    | 5701/10950 [16:10<14:55,  5.86it/s, loss=0.295]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5700): 0.8447620984911919\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  53%|█████▎    | 5801/10950 [16:27<14:36,  5.88it/s, loss=1.55]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5800): 0.924390977025032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  54%|█████▍    | 5901/10950 [16:44<14:20,  5.87it/s, loss=0.613]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5900): 0.8833153885602951\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  55%|█████▍    | 6001/10950 [17:01<14:12,  5.81it/s, loss=0.751]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6000): 0.8616415137797594\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  56%|█████▌    | 6101/10950 [17:18<13:48,  5.85it/s, loss=0.807]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6100): 0.9907212540507316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  57%|█████▋    | 6201/10950 [17:35<13:30,  5.86it/s, loss=1.14]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6200): 0.9073341369628907\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  58%|█████▊    | 6301/10950 [17:52<13:14,  5.85it/s, loss=0.162]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6300): 0.9707927165925503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  58%|█████▊    | 6401/10950 [18:09<12:55,  5.87it/s, loss=0.449]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6400): 0.9278716392815113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  59%|█████▉    | 6501/10950 [18:26<12:39,  5.86it/s, loss=1.28]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6500): 0.8643937794864178\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  60%|██████    | 6601/10950 [18:44<12:21,  5.87it/s, loss=0.752]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6600): 0.929386452883482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  61%|██████    | 6701/10950 [19:01<12:02,  5.88it/s, loss=0.749]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6700): 0.8864201568067074\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  62%|██████▏   | 6801/10950 [19:18<11:47,  5.87it/s, loss=1.13]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6800): 0.8690808126330376\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  63%|██████▎   | 6901/10950 [19:35<11:29,  5.87it/s, loss=1.06]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6900): 0.9725357773900032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  64%|██████▍   | 7001/10950 [19:52<11:14,  5.85it/s, loss=0.702]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7000): 0.8909980948269367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  65%|██████▍   | 7101/10950 [20:09<10:56,  5.86it/s, loss=1.04]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7100): 0.862824015468359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  66%|██████▌   | 7201/10950 [20:26<10:39,  5.87it/s, loss=1.4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7200): 0.9746945966780186\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  67%|██████▋   | 7301/10950 [20:43<10:21,  5.87it/s, loss=0.834]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7300): 0.9483191625773907\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  68%|██████▊   | 7401/10950 [21:00<10:06,  5.85it/s, loss=0.325]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7400): 0.8672285386919976\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  69%|██████▊   | 7501/10950 [21:17<09:49,  5.86it/s, loss=0.302]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7500): 0.8788147914409637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  69%|██████▉   | 7601/10950 [21:34<09:32,  5.85it/s, loss=1.77]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7600): 0.9038232518732547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  70%|███████   | 7701/10950 [21:51<09:12,  5.88it/s, loss=0.687]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7700): 0.9034719125926495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  71%|███████   | 7801/10950 [22:08<08:57,  5.86it/s, loss=0.628]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7800): 0.8848821716010571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  72%|███████▏  | 7901/10950 [22:25<08:39,  5.87it/s, loss=1.15]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7900): 0.9675944840908051\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  73%|███████▎  | 8001/10950 [22:42<08:24,  5.85it/s, loss=0.616]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8000): 0.9451601535081864\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  74%|███████▍  | 8101/10950 [23:00<08:05,  5.87it/s, loss=1.46]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8100): 0.9499806195497513\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  75%|███████▍  | 8201/10950 [23:17<07:49,  5.86it/s, loss=0.663]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8200): 0.9445648125559092\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  76%|███████▌  | 8301/10950 [23:34<07:31,  5.87it/s, loss=0.439]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8300): 0.9724266043305397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  77%|███████▋  | 8401/10950 [23:51<07:13,  5.87it/s, loss=1.01]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8400): 0.9185435897111893\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  78%|███████▊  | 8501/10950 [24:08<06:58,  5.86it/s, loss=0.459]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8500): 0.8802515068650245\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  79%|███████▊  | 8601/10950 [24:25<06:40,  5.86it/s, loss=1.42]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8600): 0.9024123904109002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  79%|███████▉  | 8701/10950 [24:42<06:22,  5.88it/s, loss=0.437]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8700): 0.9066160255670548\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  80%|████████  | 8801/10950 [24:59<06:05,  5.87it/s, loss=0.723]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8800): 0.8070033882558346\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  81%|████████▏ | 8901/10950 [25:16<05:51,  5.84it/s, loss=0.992]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8900): 0.8899493815004825\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  82%|████████▏ | 9001/10950 [25:33<05:30,  5.89it/s, loss=0.496]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9000): 0.9352989357709884\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  83%|████████▎ | 9101/10950 [25:50<05:14,  5.87it/s, loss=1.39]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9100): 0.8826018705219031\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  84%|████████▍ | 9201/10950 [26:07<04:57,  5.87it/s, loss=0.951]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9200): 0.9327086052298545\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  85%|████████▍ | 9301/10950 [26:24<04:41,  5.86it/s, loss=1.66]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9300): 0.8543591052293777\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  86%|████████▌ | 9401/10950 [26:41<04:23,  5.87it/s, loss=0.832]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9400): 0.8332450903952122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  87%|████████▋ | 9501/10950 [26:59<04:07,  5.85it/s, loss=0.857]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9500): 0.9325937463343144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  88%|████████▊ | 9601/10950 [27:16<03:49,  5.87it/s, loss=0.696]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9600): 0.8546927644312382\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  89%|████████▊ | 9701/10950 [27:33<03:32,  5.86it/s, loss=0.994]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9700): 0.8600543447583914\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  90%|████████▉ | 9801/10950 [27:50<03:16,  5.85it/s, loss=0.947]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9800): 0.9062267684936524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  90%|█████████ | 9901/10950 [28:07<02:59,  5.85it/s, loss=0.287]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9900): 0.9218409346044063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  91%|█████████▏| 10001/10950 [28:24<02:42,  5.85it/s, loss=0.769]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10000): 0.9056648007035255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  92%|█████████▏| 10101/10950 [28:41<02:24,  5.86it/s, loss=0.923]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10100): 0.8852294373512268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  93%|█████████▎| 10201/10950 [28:58<02:08,  5.82it/s, loss=0.553]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10200): 0.8705558234453201\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  94%|█████████▍| 10301/10950 [29:15<01:50,  5.86it/s, loss=0.805]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10300): 0.8627769563347101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  95%|█████████▍| 10401/10950 [29:32<01:33,  5.86it/s, loss=1.34]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10400): 0.9083502152562142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  96%|█████████▌| 10501/10950 [29:49<01:16,  5.87it/s, loss=1.69]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10500): 0.9421147574484349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  97%|█████████▋| 10601/10950 [30:06<00:59,  5.85it/s, loss=0.75]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10600): 0.8893396571278572\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  98%|█████████▊| 10701/10950 [30:23<00:42,  5.83it/s, loss=0.748]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10700): 0.9022189075499774\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  99%|█████████▊| 10801/10950 [30:41<00:25,  5.86it/s, loss=0.371]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10800): 0.9747663232684135\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|█████████▉| 10901/10950 [30:58<00:08,  5.87it/s, loss=0.696]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10900): 0.8945366179943085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 10950/10950 [31:06<00:00,  5.87it/s, loss=0.725]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Training Loss for Epoch 2: 0.9181046817359859\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 1322/1322 [01:11<00:00, 18.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss for Epoch 2: 1.147466570922313\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   1%|          | 101/10950 [00:17<30:53,  5.85it/s, loss=0.415]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 100): 0.6982916066795588\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   2%|▏         | 201/10950 [00:34<30:30,  5.87it/s, loss=0.772]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 200): 0.5811004158481956\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   3%|▎         | 301/10950 [00:51<30:19,  5.85it/s, loss=0.138]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 300): 0.5828841917961836\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   4%|▎         | 401/10950 [01:08<29:58,  5.87it/s, loss=0.379]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 400): 0.5347166216373443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   5%|▍         | 501/10950 [01:25<29:49,  5.84it/s, loss=0.576]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 500): 0.6827547491341829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   5%|▌         | 601/10950 [01:42<29:31,  5.84it/s, loss=0.0984]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 600): 0.6078982209414243\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   6%|▋         | 701/10950 [01:59<29:03,  5.88it/s, loss=0.621]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 700): 0.565896937251091\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   7%|▋         | 801/10950 [02:16<28:55,  5.85it/s, loss=0.566]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 800): 0.6162205328792334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   8%|▊         | 901/10950 [02:33<28:31,  5.87it/s, loss=0.514]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 900): 0.656155701354146\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   9%|▉         | 1001/10950 [02:50<28:10,  5.88it/s, loss=0.629]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1000): 0.6414738719165325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  10%|█         | 1101/10950 [03:08<28:00,  5.86it/s, loss=0.151]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1100): 0.6041491629183292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  11%|█         | 1201/10950 [03:25<27:44,  5.86it/s, loss=0.723]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1200): 0.6411497510224581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  12%|█▏        | 1301/10950 [03:42<27:28,  5.85it/s, loss=0.798]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1300): 0.6023632027208805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  13%|█▎        | 1401/10950 [03:59<27:13,  5.85it/s, loss=0.547]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1400): 0.6063440023362636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  14%|█▎        | 1501/10950 [04:16<26:53,  5.86it/s, loss=0.181]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1500): 0.616171068251133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  15%|█▍        | 1601/10950 [04:33<26:34,  5.86it/s, loss=1.26]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1600): 0.6487407328933478\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  16%|█▌        | 1701/10950 [04:50<26:12,  5.88it/s, loss=1.01]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1700): 0.6486330512911082\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  16%|█▋        | 1801/10950 [05:07<25:59,  5.87it/s, loss=0.731]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1800): 0.6380220197141171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  17%|█▋        | 1901/10950 [05:24<25:42,  5.87it/s, loss=0.6]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 1900): 0.5883560000360012\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  18%|█▊        | 2001/10950 [05:41<25:23,  5.87it/s, loss=0.963]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2000): 0.590886723920703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  19%|█▉        | 2101/10950 [05:58<25:16,  5.83it/s, loss=0.518]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2100): 0.6786312952637672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  20%|██        | 2201/10950 [06:15<24:54,  5.85it/s, loss=0.739]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2200): 0.6284412901103497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  21%|██        | 2301/10950 [06:33<24:33,  5.87it/s, loss=0.662]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2300): 0.6156789320707321\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  22%|██▏       | 2401/10950 [06:50<24:12,  5.89it/s, loss=0.629]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2400): 0.5869095500558614\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  23%|██▎       | 2501/10950 [07:07<23:57,  5.88it/s, loss=0.715]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2500): 0.6504344922304154\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  24%|██▍       | 2601/10950 [07:24<23:45,  5.86it/s, loss=1.35]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2600): 0.5959384576976299\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  25%|██▍       | 2701/10950 [07:41<23:20,  5.89it/s, loss=1.94]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2700): 0.5716405847668647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  26%|██▌       | 2801/10950 [07:58<23:05,  5.88it/s, loss=0.739]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2800): 0.6258346189185977\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  26%|██▋       | 2901/10950 [08:15<22:50,  5.87it/s, loss=0.675]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 2900): 0.6042420949041843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  27%|██▋       | 3001/10950 [08:32<22:31,  5.88it/s, loss=0.858]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3000): 0.567248505204916\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  28%|██▊       | 3101/10950 [08:49<22:21,  5.85it/s, loss=0.606]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3100): 0.6052404288202524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  29%|██▉       | 3201/10950 [09:06<22:02,  5.86it/s, loss=0.788]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3200): 0.5413550917804241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  30%|███       | 3301/10950 [09:23<21:44,  5.86it/s, loss=0.519]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3300): 0.6152820011973381\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  31%|███       | 3401/10950 [09:40<21:27,  5.86it/s, loss=0.171]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3400): 0.6604753868281841\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  32%|███▏      | 3501/10950 [09:57<21:12,  5.85it/s, loss=0.479]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3500): 0.5795098905265331\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  33%|███▎      | 3601/10950 [10:14<20:52,  5.87it/s, loss=0.844]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3600): 0.6024498764425517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  34%|███▍      | 3701/10950 [10:31<20:35,  5.87it/s, loss=0.86]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3700): 0.6346170218661428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  35%|███▍      | 3801/10950 [10:48<20:22,  5.85it/s, loss=0.755]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3800): 0.6562061517685652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  36%|███▌      | 3901/10950 [11:05<20:00,  5.87it/s, loss=1.14]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 3900): 0.5742507843673229\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  37%|███▋      | 4001/10950 [11:22<19:41,  5.88it/s, loss=0.332]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4000): 0.6392145997285843\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  37%|███▋      | 4101/10950 [11:39<19:28,  5.86it/s, loss=0.955]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4100): 0.6263213819265365\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  38%|███▊      | 4201/10950 [11:57<19:13,  5.85it/s, loss=0.805]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4200): 0.6674408518150449\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  39%|███▉      | 4301/10950 [12:14<18:54,  5.86it/s, loss=0.459]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4300): 0.5791323121637106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  40%|████      | 4401/10950 [12:31<18:39,  5.85it/s, loss=0.812]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4400): 0.5953454010933638\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  41%|████      | 4501/10950 [12:48<18:17,  5.87it/s, loss=1.09]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4500): 0.6650251422077418\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  42%|████▏     | 4601/10950 [13:05<18:00,  5.87it/s, loss=0.448]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4600): 0.6206854949891567\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  43%|████▎     | 4701/10950 [13:22<17:42,  5.88it/s, loss=0.515]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4700): 0.5891299946606159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  44%|████▍     | 4801/10950 [13:39<17:31,  5.85it/s, loss=0.574]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4800): 0.6279450680315495\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  45%|████▍     | 4901/10950 [13:56<17:08,  5.88it/s, loss=0.456]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 4900): 0.6252207854390144\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  46%|████▌     | 5001/10950 [14:13<16:53,  5.87it/s, loss=0.777]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5000): 0.5864050206542015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  47%|████▋     | 5101/10950 [14:30<16:35,  5.88it/s, loss=1.01]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5100): 0.6083432152122259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  47%|████▋     | 5201/10950 [14:47<16:20,  5.86it/s, loss=0.963]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5200): 0.6057437477633357\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  48%|████▊     | 5301/10950 [15:04<16:05,  5.85it/s, loss=0.832]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5300): 0.6199667024612426\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  49%|████▉     | 5401/10950 [15:21<15:44,  5.88it/s, loss=0.846]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5400): 0.5670528319478035\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  50%|█████     | 5501/10950 [15:38<15:29,  5.86it/s, loss=1.05]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5500): 0.5596352799981833\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  51%|█████     | 5601/10950 [15:55<15:10,  5.88it/s, loss=0.411]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5600): 0.6320634604245424\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  52%|█████▏    | 5701/10950 [16:12<14:54,  5.87it/s, loss=0.724]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5700): 0.6118320614099503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  53%|█████▎    | 5801/10950 [16:30<14:37,  5.87it/s, loss=0.285]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5800): 0.5581100994721055\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  54%|█████▍    | 5901/10950 [16:47<14:21,  5.86it/s, loss=0.207]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 5900): 0.5921534499526024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  55%|█████▍    | 6001/10950 [17:04<14:05,  5.85it/s, loss=0.244]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6000): 0.5825428801774979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  56%|█████▌    | 6101/10950 [17:21<13:47,  5.86it/s, loss=0.413]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6100): 0.6588654556125403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  57%|█████▋    | 6201/10950 [17:38<13:30,  5.86it/s, loss=0.31]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6200): 0.5995847771316767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  58%|█████▊    | 6301/10950 [17:55<13:12,  5.87it/s, loss=0.259]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6300): 0.6011570649594069\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  58%|█████▊    | 6401/10950 [18:12<13:00,  5.83it/s, loss=0.455]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6400): 0.6175738248974085\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  59%|█████▉    | 6501/10950 [18:29<12:37,  5.87it/s, loss=0.356]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6500): 0.6178614304959774\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  60%|██████    | 6601/10950 [18:46<12:21,  5.87it/s, loss=0.526]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6600): 0.5871547961235046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  61%|██████    | 6701/10950 [19:03<12:07,  5.84it/s, loss=0.609]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6700): 0.6137628005445004\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  62%|██████▏   | 6801/10950 [19:20<11:51,  5.83it/s, loss=0.565]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6800): 0.6125237777084113\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  63%|██████▎   | 6901/10950 [19:37<11:29,  5.87it/s, loss=0.937]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 6900): 0.5244058392941952\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  64%|██████▍   | 7001/10950 [19:54<11:16,  5.84it/s, loss=0.278]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7000): 0.6205209035053849\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  65%|██████▍   | 7101/10950 [20:11<10:56,  5.86it/s, loss=0.849]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7100): 0.5408771743625402\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  66%|██████▌   | 7201/10950 [20:28<10:40,  5.86it/s, loss=1.01]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7200): 0.6291651917248964\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  67%|██████▋   | 7301/10950 [20:46<10:20,  5.88it/s, loss=0.395]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7300): 0.6341906989365816\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  68%|██████▊   | 7401/10950 [21:03<10:06,  5.85it/s, loss=0.698]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7400): 0.5669528485834598\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  69%|██████▊   | 7501/10950 [21:20<09:50,  5.84it/s, loss=0.589]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7500): 0.589189855530858\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  69%|██████▉   | 7601/10950 [21:37<09:30,  5.87it/s, loss=0.497]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7600): 0.5908721781894565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  70%|███████   | 7701/10950 [21:54<09:11,  5.89it/s, loss=0.295]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7700): 0.6046503009647131\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  71%|███████   | 7801/10950 [22:11<08:55,  5.88it/s, loss=0.455]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7800): 0.5745651093125344\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  72%|███████▏  | 7901/10950 [22:28<08:38,  5.88it/s, loss=0.262]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 7900): 0.5936830637603998\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  73%|███████▎  | 8001/10950 [22:45<08:24,  5.84it/s, loss=1.39]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8000): 0.5555706376582384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  74%|███████▍  | 8101/10950 [23:02<08:04,  5.88it/s, loss=0.493]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8100): 0.6066849126666785\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  75%|███████▍  | 8201/10950 [23:19<07:48,  5.87it/s, loss=1.01]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8200): 0.6068078721314669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  76%|███████▌  | 8301/10950 [23:36<07:31,  5.87it/s, loss=0.999]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8300): 0.5770673416554928\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  77%|███████▋  | 8401/10950 [23:53<07:14,  5.86it/s, loss=0.484]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8400): 0.6199776013195515\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  78%|███████▊  | 8501/10950 [24:10<06:56,  5.88it/s, loss=0.728]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8500): 0.5715317110717296\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  79%|███████▊  | 8601/10950 [24:27<06:41,  5.85it/s, loss=0.423]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8600): 0.6018045489490033\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  79%|███████▉  | 8701/10950 [24:44<06:23,  5.86it/s, loss=0.217]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8700): 0.6094974578917026\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  80%|████████  | 8801/10950 [25:02<06:04,  5.89it/s, loss=0.706]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8800): 0.5820247787237167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  81%|████████▏ | 8901/10950 [25:19<05:48,  5.88it/s, loss=0.455]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 8900): 0.6212674327939749\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  82%|████████▏ | 9001/10950 [25:36<05:31,  5.88it/s, loss=0.491]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9000): 0.5561422229558229\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  83%|████████▎ | 9101/10950 [25:53<05:16,  5.84it/s, loss=0.781]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9100): 0.5843381467461586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  84%|████████▍ | 9201/10950 [26:10<04:58,  5.86it/s, loss=0.452]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9200): 0.6093230287730694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  85%|████████▍ | 9301/10950 [26:27<04:40,  5.87it/s, loss=0.547]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9300): 0.5683894060179591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  86%|████████▌ | 9401/10950 [26:44<04:24,  5.86it/s, loss=0.636]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9400): 0.5572957564145327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  87%|████████▋ | 9501/10950 [27:01<04:06,  5.88it/s, loss=0.454]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9500): 0.6409769594669342\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  88%|████████▊ | 9601/10950 [27:18<03:50,  5.85it/s, loss=0.876]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9600): 0.5123872531950474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  89%|████████▊ | 9701/10950 [27:35<03:32,  5.86it/s, loss=0.508]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9700): 0.6233972778171301\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  90%|████████▉ | 9801/10950 [27:52<03:16,  5.85it/s, loss=1.33]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9800): 0.581683349609375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  90%|█████████ | 9901/10950 [28:09<02:58,  5.87it/s, loss=0.988]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 9900): 0.6787943036109209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  91%|█████████▏| 10001/10950 [28:26<02:41,  5.88it/s, loss=0.903]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10000): 0.5493169967085123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  92%|█████████▏| 10101/10950 [28:43<02:25,  5.83it/s, loss=0.303]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10100): 0.6226316587626934\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  93%|█████████▎| 10201/10950 [29:00<02:08,  5.84it/s, loss=0.245]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10200): 0.5330405846983194\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  94%|█████████▍| 10301/10950 [29:17<01:50,  5.88it/s, loss=1.04]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10300): 0.5834126925468445\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  95%|█████████▍| 10401/10950 [29:35<01:33,  5.89it/s, loss=0.585]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10400): 0.6033886218070984\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  96%|█████████▌| 10501/10950 [29:52<01:16,  5.84it/s, loss=0.206]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10500): 0.5905494809150695\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  97%|█████████▋| 10601/10950 [30:09<00:59,  5.83it/s, loss=0.513]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10600): 0.5066306424885988\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  98%|█████████▊| 10701/10950 [30:26<00:42,  5.87it/s, loss=0.769]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10700): 0.5143914371356368\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  99%|█████████▊| 10801/10950 [30:43<00:25,  5.85it/s, loss=1.2]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10800): 0.566112012937665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|█████████▉| 10901/10950 [31:00<00:08,  5.86it/s, loss=0.556]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average loss of the last 100 batches (batch 10900): 0.625988946184516\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 10950/10950 [31:08<00:00,  5.86it/s, loss=0.36]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Training Loss for Epoch 3: 0.6020535657558267\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validating: 100%|██████████| 1322/1322 [01:11<00:00, 18.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss for Epoch 3: 1.3187899800967116\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForQuestionAnswering, AdamW, get_scheduler\n",
        "import torch\n",
        "from tqdm import tqdm  # Progress bar\n",
        "\n",
        "# Load the pre-trained BERT model for question answering\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased')\n",
        "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Set up the optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5)\n",
        "num_epochs = 3\n",
        "\n",
        "# Set up the learning rate scheduler\n",
        "num_training_steps = num_epochs * len(train_loader)\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "# Set device (GPU or CPU)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# Training loop with printing average loss every 100 batches\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "    # Train the model\n",
        "    total_train_loss = 0\n",
        "    batch_losses = []  # To track the losses of the last 100 batches\n",
        "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
        "\n",
        "    for batch_idx, batch in enumerate(progress_bar):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}  # Move data to the device\n",
        "        outputs = model(**batch)  # Forward pass\n",
        "        loss = outputs.loss\n",
        "        total_train_loss += loss.item()\n",
        "        batch_losses.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update parameters\n",
        "        lr_scheduler.step()  # Update learning rate\n",
        "\n",
        "        # Print the average loss for the last 100 batches\n",
        "        if (batch_idx + 1) % 100 == 0:\n",
        "            avg_last_100_batches = sum(batch_losses[-100:]) / len(batch_losses[-100:])\n",
        "            print(f\"Average loss of the last 100 batches (batch {batch_idx + 1}): {avg_last_100_batches}\")\n",
        "\n",
        "        # Update progress bar with the current loss\n",
        "        progress_bar.set_postfix({\"loss\": loss.item()})\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    print(f\"Average Training Loss for Epoch {epoch + 1}: {avg_train_loss}\")\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    progress_bar = tqdm(dev_loader, desc=\"Validating\")\n",
        "    for batch in progress_bar:\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)  # Forward pass (without computing gradients)\n",
        "            loss = outputs.loss\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(dev_loader)\n",
        "    print(f\"Validation Loss for Epoch {epoch + 1}: {avg_val_loss}\")\n",
        "\n",
        "    # Set model back to training mode\n",
        "    model.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqXMosLZTtgZ",
        "outputId": "e2d51f3c-2288-4aaa-e86b-0dea839e7686"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the directory where you want to save the model\n",
        "model_save_path = '/content/drive/My Drive/SQuAD_datasets/saved_model'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(model_save_path):\n",
        "    os.makedirs(model_save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMs1u8n5T4vc",
        "outputId": "834f91d7-f271-4601-ba3b-2177ba00eb1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer saved to /content/drive/My Drive/SQuAD_datasets/saved_model\n"
          ]
        }
      ],
      "source": [
        "# Save the trained model and tokenizer\n",
        "model.save_pretrained(model_save_path)\n",
        "tokenizer.save_pretrained(model_save_path)\n",
        "\n",
        "print(f\"Model and tokenizer saved to {model_save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjxZ48s9UJnh",
        "outputId": "5feb0120-6218-4cbb-9e38-88c623c68f17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertForQuestionAnswering, BertTokenizer\n",
        "\n",
        "# Load the saved model and tokenizer from Google Drive\n",
        "model = BertForQuestionAnswering.from_pretrained(model_save_path)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_save_path)\n",
        "\n",
        "print(\"Model and tokenizer loaded successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRK0VTh173Gl",
        "outputId": "dff54031-f938-42a7-b338-112386ab5792"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForQuestionAnswering(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertForQuestionAnswering, BertTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the saved model and tokenizer from Google Drive\n",
        "model_save_path = '/content/drive/My Drive/SQuAD_datasets/saved_model'\n",
        "model = BertForQuestionAnswering.from_pretrained(model_save_path)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_save_path)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "raRhHeWBUqyK"
      },
      "outputs": [],
      "source": [
        "def answer_question(question, context):\n",
        "    # Tokenize input\n",
        "    inputs = tokenizer(question, context, return_tensors='pt', truncation=True, max_length=512).to(device)\n",
        "\n",
        "    # Generate output\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get the most likely beginning and end of the answer span\n",
        "    answer_start_scores = outputs.start_logits\n",
        "    answer_end_scores = outputs.end_logits\n",
        "\n",
        "    # Find the tokens with the highest `start` and `end` scores\n",
        "    answer_start = torch.argmax(answer_start_scores)  # Get the most likely start of the answer\n",
        "    answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of the answer\n",
        "\n",
        "    # Convert the tokens to text\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
        "\n",
        "    return answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6LsW9xIUvw2",
        "outputId": "e955dd8c-9741-48f7-8142-af0625b9d239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Who won Super Bowl 50?\n",
            "Answer: denver broncos\n"
          ]
        }
      ],
      "source": [
        "# Example context and question\n",
        "context = \"\"\"Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season.\n",
        "The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10\n",
        "to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California.\"\"\"\n",
        "\n",
        "question = \"Who won Super Bowl 50?\"\n",
        "\n",
        "# Get the answer\n",
        "answer = answer_question(question, context)\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7ncZDXNVGrO",
        "outputId": "264801e1-6c90-4980-d0b6-380983fa1c26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Who designed the Eiffel Tower?\n",
            "Answer: gustave eiffel\n"
          ]
        }
      ],
      "source": [
        "# New example context and question (completely different from training or dev data)\n",
        "context = \"\"\"\n",
        "The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel,\n",
        "whose company designed and built the tower. Constructed from 1887 to 1889 as the entrance arch for the 1889 World's Fair,\n",
        "it was initially criticized by some of France's leading artists and intellectuals for its design, but it has become a global cultural icon of France\n",
        "and one of the most recognizable structures in the world.\n",
        "\"\"\"\n",
        "\n",
        "question = \"Who designed the Eiffel Tower?\"\n",
        "\n",
        "# Get the answer from the model\n",
        "answer = answer_question(question, context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SMlTj77VT6w",
        "outputId": "bb2bd8a0-5fff-4e50-d61f-101ab451e567"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is Eiffel Tower made up of?\n",
            "Answer: wrought - iron lattice tower\n"
          ]
        }
      ],
      "source": [
        "question = \"What is Eiffel Tower made up of?\"\n",
        "\n",
        "# Get the answer from the model\n",
        "answer = answer_question(question, context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIfeKuoCVmH0",
        "outputId": "3b2fac16-c513-46c6-bd4e-a888362fb230"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: How long it took to build the Eiffel Tower?\n",
            "Answer: from 1887 to 1889\n"
          ]
        }
      ],
      "source": [
        "question = \"How long it took to build the Eiffel Tower?\"\n",
        "\n",
        "# Get the answer from the model\n",
        "answer = answer_question(question, context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-ouyXbrVxgy",
        "outputId": "59371cb9-25ce-4f03-86f3-4f7a8c1f4d4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Why was the construction of Eiffel Tower critisized initally?\n",
            "Answer: it was initially criticized by some of france ' s leading artists and intellectuals for its design\n"
          ]
        }
      ],
      "source": [
        "question = \"Why was the construction of Eiffel Tower critisized initally?\"\n",
        "\n",
        "# Get the answer from the model\n",
        "answer = answer_question(question, context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "FTPTSZa-WjsB",
        "outputId": "da009549-b0fc-42b3-b8fb-4916a885191b"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_ed38a4df-1a39-4ac9-8d7a-9696ee6c59d7\", \"saved_model.zip\", 403697882)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "# Zip the saved model directory\n",
        "shutil.make_archive('/content/saved_model', 'zip', '/content/drive/My Drive/SQuAD_datasets/saved_model')\n",
        "\n",
        "# Download the zip file to your PC\n",
        "from google.colab import files\n",
        "files.download('/content/saved_model.zip')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### After downloading the model in Local Laptop, the model was saved to the working directory and zip extracted.\n",
        "\n",
        "### This part was executed in the local laptop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['C:\\\\Users\\\\CZ0068\\\\torch', 'C:\\\\Users\\\\CZ0068\\\\torch', 'C:\\\\Users\\\\CZ0068\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311, C:\\\\Users\\\\CZ0068\\\\torch', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\python311.zip', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\DLLs', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\Lib', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0', '', 'C:\\\\Users\\\\CZ0068\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\CZ0068\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\CZ0068\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\CZ0068\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\Pythonwin', 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\Lib\\\\site-packages']\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\CZ0068\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.45.2\n",
            "2.4.1+cpu\n",
            "1.24.4\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.insert(0, 'C:\\\\Users\\\\CZ0068\\\\torch')\n",
        "\n",
        "import transformers\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "print(transformers.__version__)\n",
        "print(torch.__version__)\n",
        "print(np.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Name some models that are based on the Transformer architecture\n",
            "Answer: BERT, GPT, and T5\n",
            "Question: What mechanism does the Transformer rely on\n",
            "Answer: Self-attention mechanisms\n",
            "Question: Why are Transformers faster than traditional RNNs?\n",
            "Answer: Self-attention mechanisms\n",
            "Question: What happens if selef-attention mechanism capture the relationship between different parts of a sequence ?\n",
            "Answer: Self-attention mechanisms to capture the relationships between different parts of a sequence. This allows Transformers to process data in parallel\n",
            "Question: State some applications of Transformers?\n",
            "Answer: Machine translation, text generation, and question answering\n",
            "Question: Who introduced self Attention?\n",
            "Answer: Vaswani et al.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertForQuestionAnswering, BertTokenizerFast\n",
        "\n",
        "# Path to the extracted model on your PC\n",
        "model_path = 'D:/Rajesh/Rajesh/Personal/AISanDiego/520-NLP/Project/saved_model/'\n",
        "\n",
        "# Load the model and the fast version of the tokenizer\n",
        "model = BertForQuestionAnswering.from_pretrained(model_path)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
        "\n",
        "# Define a function to answer questions\n",
        "def answer_question(question, context):\n",
        "    # Encode the inputs with offset mappings to preserve context token positions\n",
        "    inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\", add_special_tokens=True, return_offsets_mapping=True)\n",
        "    \n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "    offsets = inputs[\"offset_mapping\"][0]  # Offset mapping for token positions\n",
        "    \n",
        "    # Get the answer using the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        answer_start_scores = outputs.start_logits\n",
        "        answer_end_scores = outputs.end_logits\n",
        "\n",
        "    # Find the start and end of the answer\n",
        "    answer_start = torch.argmax(answer_start_scores)\n",
        "    answer_end = torch.argmax(answer_end_scores) + 1\n",
        "\n",
        "    # Get the token offsets for the answer (start and end positions)\n",
        "    start_char = offsets[answer_start][0]\n",
        "    end_char = offsets[answer_end - 1][1]\n",
        "\n",
        "    # Extract the answer from the original context using the offsets\n",
        "    answer = context[start_char:end_char]\n",
        "    \n",
        "    # Capitalize the first letter of the answer if needed\n",
        "    if answer:\n",
        "        answer = answer[0].upper() + answer[1:]\n",
        "\n",
        "    return answer\n",
        "\n",
        "# Test with a new question and context\n",
        "context = (\"Transformers are a type of deep learning model introduced in the paper 'Attention is All You Need' by Vaswani et al. \"\n",
        "           \"in 2017. Unlike traditional recurrent neural networks (RNNs), Transformers rely entirely on self-attention mechanisms \"\n",
        "           \"to capture the relationships between different parts of a sequence. This allows Transformers to process data in parallel, \"\n",
        "           \"making them much faster and more efficient for tasks like natural language processing. Transformers are the foundation for \"\n",
        "           \"many state-of-the-art models, such as BERT, GPT, and T5. They are used in a variety of applications, including machine translation, \"\n",
        "           \"text generation, and question answering.\")\n",
        "\n",
        "\n",
        "\n",
        "question = \"Name some models that are based on the Transformer architecture\"\n",
        "answer = answer_question(question, context)\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")\n",
        "\n",
        "\n",
        "question = \"What mechanism does the Transformer rely on\"\n",
        "answer = answer_question(question, context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer_question(question, context)}\")\n",
        "\n",
        "question = \"Why are Transformers faster than traditional RNNs?\"\n",
        "answer = answer_question(question, context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer_question(question, context)}\")\n",
        "\n",
        "\n",
        "question = \"What happens if selef-attention mechanism capture the relationship between different parts of a sequence ?\"\n",
        "answer = answer_question(question, context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer_question(question, context)}\")\n",
        "\n",
        "question = \"State some applications of Transformers?\"\n",
        "answer = answer_question(question, context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer_question(question, context)}\")\n",
        "\n",
        "question = \"Who introduced self Attention?\"\n",
        "answer = answer_question(question, context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer_question(question, context)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Name some models that are based on the Transformer architecture\n",
            "Answer: Bert, gpt, and t5\n",
            "Question: What mechanism does the Transformer rely on\n",
            "Answer: Self - attention mechanisms\n",
            "Question: Why are Transformers faster than traditional RNNs?\n",
            "Answer: Transformers rely entirely on self - attention mechanisms to capture the relationships between different parts of a sequence\n",
            "Question: What happens if selef-attention mechanism capture the relationship between different parts of a sequence ?\n",
            "Answer: Allows transformers to process data in parallel\n",
            "Question: State some applications of Transformers?\n",
            "Answer: Machine translation, text generation, and question answering\n",
            "Question: Who introduced self Attention?\n",
            "Answer: Vaswani et al.\n"
          ]
        }
      ],
      "source": [
        "def answer_question(question, context):\n",
        "    # Tokenize input\n",
        "    inputs = tokenizer(question, context, return_tensors='pt', truncation=True, max_length=512)\n",
        "\n",
        "    # Generate output\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get the most likely beginning and end of the answer span\n",
        "    answer_start_scores = outputs.start_logits\n",
        "    answer_end_scores = outputs.end_logits\n",
        "\n",
        "    # Find the tokens with the highest `start` and `end` scores\n",
        "    answer_start = torch.argmax(answer_start_scores)  # Get the most likely start of the answer\n",
        "    answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of the answer\n",
        "\n",
        "    # Convert the tokens to text\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
        "\n",
        "    answer=answer[0].upper()+ answer[1:len(answer)]\n",
        "\n",
        "    return answer\n",
        "\n",
        "# Test with a new question and context\n",
        "context = (\"Transformers are a type of deep learning model introduced in the paper 'Attention is All You Need' by Vaswani et al. \"\n",
        "           \"in 2017. Unlike traditional recurrent neural networks (RNNs), Transformers rely entirely on self-attention mechanisms \"\n",
        "           \"to capture the relationships between different parts of a sequence. This allows Transformers to process data in parallel, \"\n",
        "           \"making them much faster and more efficient for tasks like natural language processing. Transformers are the foundation for \"\n",
        "           \"many state-of-the-art models, such as BERT, GPT, and T5. They are used in a variety of applications, including machine translation, \"\n",
        "           \"text generation, and question answering.\")\n",
        "question = \"Name some models that are based on the Transformer architecture\"\n",
        "answer = answer_question(question, context)\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")\n",
        "\n",
        "\n",
        "question = \"What mechanism does the Transformer rely on\"\n",
        "answer = answer_question(question, context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer_question(question, context)}\")\n",
        "\n",
        "question = \"Why are Transformers faster than traditional RNNs?\"\n",
        "answer = answer_question(question, context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer_question(question, context)}\")\n",
        "\n",
        "\n",
        "question = \"What happens if selef-attention mechanism capture the relationship between different parts of a sequence ?\"\n",
        "answer = answer_question(question, context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer_question(question, context)}\")\n",
        "\n",
        "question = \"State some applications of Transformers?\"\n",
        "answer = answer_question(question, context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer_question(question, context)}\")\n",
        "\n",
        "question = \"Who introduced self Attention?\"\n",
        "answer = answer_question(question, context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer_question(question, context)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are some of the key developments in artificial intelligence from its early days to the present?\n",
            "Answer: Problem-solving, learning, planning, natural language understanding, and perception. The term was first coined by John McCarthy in 1956 at the Dartmouth Conference, which is considered the founding event of AI as a field. Early efforts in AI involved symbolic AI, where knowledge was explicitly codedinto machines, but progress was slow due to the complexity of human cognition. In the 1990s and 2000s, a major shift occurred with the rise of machine learning,a subset of AI that enables computers to learn from data. Instead of being explicitly programmed, machine learning algorithms\n"
          ]
        }
      ],
      "source": [
        "# Test with a new question and context\n",
        "context = (\"Artificial intelligence (AI) is a field of computer science that aims to create machines that can perform tasks that would normally require human intelligence.\"\n",
        "           \"These tasks include problem-solving, learning, planning, natural language understanding, and perception. The term was first coined by John McCarthy in 1956 at \"\n",
        "           \"the Dartmouth Conference, which is considered the founding event of AI as a field. Early efforts in AI involved symbolic AI, where knowledge was explicitly coded\"\n",
        "           \"into machines, but progress was slow due to the complexity of human cognition. In the 1990s and 2000s, a major shift occurred with the rise of machine learning,\"\n",
        "            \"a subset of AI that enables computers to learn from data. Instead of being explicitly programmed, machine learning algorithms, especially neural networks, became\" \n",
        "            \"capable of automatically improving their performance on tasks. Deep learning, a branch of machine learning involving multi-layered neural networks, has enabled\"\n",
        "            \"breakthroughs in fields like image recognition, speech processing, and game playing.Today, AI is applied in numerous industries including healthcare, finance,\"\n",
        "            \" and autonomous driving. While AI has made tremendous progress, it also raises ethical concerns such as bias in algorithms, job displacement, and the need for\" \n",
        "            \"regulations to ensure AI systems are fair and transparent. Despite these challenges, AI continues to evolve rapidly, with researchers aiming to achieve artificial\" \n",
        "            \"general intelligence (AGI), a level of AI that can understand and learn any intellectual task that a human being can.\")\n",
        "\n",
        "question = \"What are some of the key developments in artificial intelligence from its early days to the present?\"\n",
        "answer = answer_question(question, context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What are some ethical concerns related to artificial intelligence?\n",
            "Answer: Bias in algorithms, job displacement, and the need forregulations to ensure AI systems are fair and transparent\n"
          ]
        }
      ],
      "source": [
        "question = \"What are some ethical concerns related to artificial intelligence?\"\n",
        "answer = answer_question(question, context)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "278a824bca1745f5b235d916cd62c677": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1348a6856f54c55974f1bcf94fdeb54",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b1f2795378646b8b051a163a0f3299c",
            "value": 440449768
          }
        },
        "2ac43049cd264c8ea1b034bbe26223d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ff7180bcb1b44c8ba5e1f10e63bfeef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3271d85a4e1b463d907f1ed429695224": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ff7180bcb1b44c8ba5e1f10e63bfeef",
            "placeholder": "​",
            "style": "IPY_MODEL_cdef2072ebd5467b9f80cd7f74639dc9",
            "value": "model.safetensors: 100%"
          }
        },
        "3b1f2795378646b8b051a163a0f3299c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ceb5298c51745fdb1393163029cdcd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f9ab103b36b4b8097a8caea323c589b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75b039342e57402eb33b2cc4de0ee415",
            "placeholder": "​",
            "style": "IPY_MODEL_3ceb5298c51745fdb1393163029cdcd9",
            "value": " 440M/440M [00:02&lt;00:00, 269MB/s]"
          }
        },
        "75b039342e57402eb33b2cc4de0ee415": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b50b02e4de24a8bb150576ab725fd38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3271d85a4e1b463d907f1ed429695224",
              "IPY_MODEL_278a824bca1745f5b235d916cd62c677",
              "IPY_MODEL_3f9ab103b36b4b8097a8caea323c589b"
            ],
            "layout": "IPY_MODEL_2ac43049cd264c8ea1b034bbe26223d7"
          }
        },
        "cdef2072ebd5467b9f80cd7f74639dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1348a6856f54c55974f1bcf94fdeb54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
