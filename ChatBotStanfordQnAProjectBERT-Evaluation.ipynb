{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\CZ0068\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\CZ0068\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Name some models that are based on the Transformer architecture\n",
            "Predicted Answer: Bert, gpt, and t5\n",
            "Ground Truth: BERT, GPT, and T5\n",
            "Precision: 1.00, Recall: 1.00, F1 Score: 1.00, Accuracy: 1.00\n",
            "BLEU Score: 1.00, Cosine Similarity: 1.00\n",
            "\n",
            "Question: What mechanism does the Transformer rely on\n",
            "Predicted Answer: Self - attention mechanisms\n",
            "Ground Truth: Self-attention mechanisms\n",
            "Precision: 1.00, Recall: 1.00, F1 Score: 1.00, Accuracy: 1.00\n",
            "BLEU Score: 1.00, Cosine Similarity: 1.00\n",
            "\n",
            "Question: Why are Transformers faster than traditional RNNs?\n",
            "Predicted Answer: Transformers rely entirely on self - attention mechanisms to capture the relationships between different parts of a sequence\n",
            "Ground Truth: Transformers rely entirely on self-attention mechanisms, which captures the relationship between different parts of a sentence\n",
            "Precision: 0.42, Recall: 0.42, F1 Score: 0.42, Accuracy: 0.42\n",
            "BLEU Score: 0.57, Cosine Similarity: 0.94\n",
            "\n",
            "Question: What happens if self-attention mechanism captures the relationship between different parts of a sequence?\n",
            "Predicted Answer: Allows transformers to process data in parallel\n",
            "Ground Truth: Transformers can process data in parallel\n",
            "Precision: 0.00, Recall: 0.00, F1 Score: 0.00, Accuracy: 0.00\n",
            "BLEU Score: 0.43, Cosine Similarity: 0.87\n",
            "\n",
            "Question: State some applications of Transformers?\n",
            "Predicted Answer: Machine translation, text generation, and question answering\n",
            "Ground Truth: Machine translation, text generation, and question answering\n",
            "Precision: 1.00, Recall: 1.00, F1 Score: 1.00, Accuracy: 1.00\n",
            "BLEU Score: 1.00, Cosine Similarity: 1.00\n",
            "\n",
            "Question: Who introduced self Attention?\n",
            "Predicted Answer: Vaswani et al.\n",
            "Ground Truth: Vaswani et al.\n",
            "Precision: 1.00, Recall: 1.00, F1 Score: 1.00, Accuracy: 1.00\n",
            "BLEU Score: 1.00, Cosine Similarity: 1.00\n",
            "\n",
            "Consolidated Precision: 0.74\n",
            "Consolidated Recall: 0.74\n",
            "Consolidated F1 Score: 0.74\n",
            "Consolidated Token-Level Accuracy: 0.74\n",
            "Consolidated BLEU Score: 0.83\n",
            "Consolidated Cosine Similarity: 0.97\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertForQuestionAnswering, BertTokenizerFast, BertModel\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "# Download NLTK data for BLEU score if needed\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model_path = 'D:/Rajesh/Rajesh/Personal/AISanDiego/520-NLP/Project/saved_model/'\n",
        "model = BertForQuestionAnswering.from_pretrained(model_path)\n",
        "embedding_model = BertModel.from_pretrained('bert-base-uncased')  # Use BertModel for embeddings\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
        "\n",
        "# Function to compute cosine similarity using hidden states (embeddings)\n",
        "def compute_cosine_similarity(text1, text2):\n",
        "    # Tokenize the inputs\n",
        "    inputs_1 = tokenizer(text1, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    inputs_2 = tokenizer(text2, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "    # Get hidden states (sentence embeddings) from embedding model\n",
        "    with torch.no_grad():\n",
        "        outputs_1 = embedding_model(**inputs_1)\n",
        "        outputs_2 = embedding_model(**inputs_2)\n",
        "\n",
        "    # Extract the CLS token embeddings\n",
        "    embedding_1 = outputs_1.last_hidden_state[:, 0, :].numpy()\n",
        "    embedding_2 = outputs_2.last_hidden_state[:, 0, :].numpy()\n",
        "\n",
        "    # Compute cosine similarity between the embeddings\n",
        "    similarity = cosine_similarity(embedding_1, embedding_2)[0][0]\n",
        "    return similarity\n",
        "\n",
        "# Function to align token lengths by padding shorter lists with dummy tokens\n",
        "def align_token_lengths(true_tokens, pred_tokens):\n",
        "    max_len = max(len(true_tokens), len(pred_tokens))\n",
        "    true_tokens += ['[PAD]'] * (max_len - len(true_tokens))\n",
        "    pred_tokens += ['[PAD]'] * (max_len - len(pred_tokens))\n",
        "    return true_tokens, pred_tokens\n",
        "\n",
        "# Function to answer questions and calculate metrics\n",
        "def answer_question_with_metrics(question, context, ground_truth):\n",
        "    inputs = tokenizer(question, context, return_tensors='pt', truncation=True, max_length=512)\n",
        "\n",
        "    # Generate the answer using the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get the most likely beginning and end of the answer span\n",
        "    answer_start = torch.argmax(outputs.start_logits)\n",
        "    answer_end = torch.argmax(outputs.end_logits) + 1\n",
        "\n",
        "    # Convert the tokens to text\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
        "\n",
        "    # Capitalize the first letter of the answer\n",
        "    answer = answer[0].upper() + answer[1:]\n",
        "\n",
        "    # Tokenize predicted answer and ground truth for token-level comparison\n",
        "    pred_tokens = tokenizer.tokenize(answer)\n",
        "    true_tokens = tokenizer.tokenize(ground_truth)\n",
        "\n",
        "    # Align token lengths to avoid length mismatches\n",
        "    true_tokens, pred_tokens = align_token_lengths(true_tokens, pred_tokens)\n",
        "\n",
        "    # Calculate token-level precision, recall, F1\n",
        "    precision = precision_score(true_tokens, pred_tokens, average='micro') if true_tokens else 0\n",
        "    recall = recall_score(true_tokens, pred_tokens, average='micro') if true_tokens else 0\n",
        "    f1 = f1_score(true_tokens, pred_tokens, average='micro') if true_tokens else 0\n",
        "\n",
        "    # Token accuracy\n",
        "    token_accuracy = sum([p == t for p, t in zip(pred_tokens, true_tokens)]) / len(true_tokens) if true_tokens else 0\n",
        "\n",
        "    # Calculate BLEU score\n",
        "    smoothing_fn = SmoothingFunction().method1\n",
        "    bleu_score = sentence_bleu([true_tokens], pred_tokens, smoothing_function=smoothing_fn)\n",
        "\n",
        "    # Calculate Cosine Similarity\n",
        "    cosine_sim = compute_cosine_similarity(answer, ground_truth)\n",
        "\n",
        "    return answer, precision, recall, f1, token_accuracy, bleu_score, cosine_sim\n",
        "\n",
        "# Example context and questions\n",
        "context = (\"Transformers are a type of deep learning model introduced in the paper 'Attention is All You Need' by Vaswani et al. \"\n",
        "           \"in 2017. Unlike traditional recurrent neural networks (RNNs), Transformers rely entirely on self-attention mechanisms \"\n",
        "           \"to capture the relationships between different parts of a sequence. This allows Transformers to process data in parallel, \"\n",
        "           \"making them much faster and more efficient for tasks like natural language processing. Transformers are the foundation for \"\n",
        "           \"many state-of-the-art models, such as BERT, GPT, and T5. They are used in a variety of applications, including machine translation, \"\n",
        "           \"text generation, and question answering.\")\n",
        "\n",
        "questions = [\n",
        "    \"Name some models that are based on the Transformer architecture\",\n",
        "    \"What mechanism does the Transformer rely on\",\n",
        "    \"Why are Transformers faster than traditional RNNs?\",\n",
        "    \"What happens if self-attention mechanism captures the relationship between different parts of a sequence?\",\n",
        "    \"State some applications of Transformers?\",\n",
        "    \"Who introduced self Attention?\"\n",
        "]\n",
        "\n",
        "ground_truths = [\n",
        "    \"BERT, GPT, and T5\",\n",
        "    \"Self-attention mechanisms\",\n",
        "    \"Transformers rely entirely on self-attention mechanisms, which captures the relationship between different parts of a sentence\",\n",
        "    \"Transformers can process data in parallel\",\n",
        "    \"Machine translation, text generation, and question answering\",\n",
        "    \"Vaswani et al.\"\n",
        "]\n",
        "\n",
        "# Initialize totals for overall metrics\n",
        "total_precision, total_recall, total_f1, total_accuracy, total_bleu, total_cosine_sim = 0, 0, 0, 0, 0, 0\n",
        "num_questions = len(questions)\n",
        "\n",
        "# Store the results\n",
        "for question, truth in zip(questions, ground_truths):\n",
        "    answer, precision, recall, f1, token_accuracy, bleu_score, cosine_sim = answer_question_with_metrics(question, context, truth)\n",
        "    \n",
        "    # Print individual results\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Predicted Answer: {answer}\")\n",
        "    print(f\"Ground Truth: {truth}\")\n",
        "    print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}, Accuracy: {token_accuracy:.2f}\")\n",
        "    print(f\"BLEU Score: {bleu_score:.2f}, Cosine Similarity: {cosine_sim:.2f}\\n\")\n",
        "\n",
        "    # Accumulate the metrics for overall calculation\n",
        "    total_precision += precision\n",
        "    total_recall += recall\n",
        "    total_f1 += f1\n",
        "    total_accuracy += token_accuracy\n",
        "    total_bleu += bleu_score\n",
        "    total_cosine_sim += cosine_sim\n",
        "\n",
        "# Calculate and print the consolidated metrics\n",
        "avg_precision = total_precision / num_questions\n",
        "avg_recall = total_recall / num_questions\n",
        "avg_f1 = total_f1 / num_questions\n",
        "avg_accuracy = total_accuracy / num_questions\n",
        "avg_bleu = total_bleu / num_questions\n",
        "avg_cosine_sim = total_cosine_sim / num_questions\n",
        "\n",
        "print(f\"Consolidated Precision: {avg_precision:.2f}\")\n",
        "print(f\"Consolidated Recall: {avg_recall:.2f}\")\n",
        "print(f\"Consolidated F1 Score: {avg_f1:.2f}\")\n",
        "print(f\"Consolidated Token-Level Accuracy: {avg_accuracy:.2f}\")\n",
        "print(f\"Consolidated BLEU Score: {avg_bleu:.2f}\")\n",
        "print(f\"Consolidated Cosine Similarity: {avg_cosine_sim:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When evaluating language models using strict token-level metrics like precision, recall, F1 score, and accuracy does not give meaningful results. These metrics focus on exact word matches between the predicted and ground truth answers, which can lead to low scores even if the answers are semantically correct but have slight variations in wording. We are reporting these token level metrics for completeness\n",
        "\n",
        "### Explanation of the metrics:\n",
        "1. **Precision, Recall, and F1 Score (Token-level):**\n",
        "   - **Precision** measures how many of the predicted tokens are correct compared to the ground truth.\n",
        "   - **Recall** measures how many of the ground truth tokens are captured in the prediction.\n",
        "   - **F1 Score** is the harmonic mean of precision and recall.\n",
        "   - These metrics work well for tasks where exact matches are required (e.g., named entity recognition) but are not ideal for tasks like question answering where meaning matters more than exact word matches.\n",
        "\n",
        "   In our case:\n",
        "   - **For \"Why are Transformers faster than traditional RNNs?\"**:\n",
        "     - The predicted and ground truth answers are semantically the same, but the difference in phrases like \"parts of a sequence\" vs. \"parts of a sentence\" results in lower precision, recall, and F1 scores.\n",
        "   - **For \"What happens if self-attention mechanism captures...?\"**:\n",
        "     - The difference between \"Allows transformers to process data in parallel\" and \"Transformers can process data in parallel\" leads to 0 token-level scores, even though the meaning is correct.\n",
        "\n",
        "2. **BLEU Score**:\n",
        "   - BLEU focuses on the n-gram overlap between predicted and ground truth answers. It can give some credit for partial matches but doesn't handle paraphrasing well. Hence, it gives a moderate score (e.g., 0.57 and 0.43), indicating partial overlap but not full matches.\n",
        "\n",
        "3. **Cosine Similarity**:\n",
        "   - Cosine similarity between embeddings gives a much better indication of semantic similarity. High scores (e.g., 0.94 and 0.87) indicate that the predicted and ground truth answers are semantically very similar, despite minor word differences.\n",
        "\n",
        "### What this means:\n",
        "The token-level metrics (precision, recall, F1, accuracy) are giving a misleading picture in this case because they penalize minor wording differences. BLEU score provides some improvement, but cosine similarity gives the most accurate reflection of how similar the answers are in meaning.\n",
        "\n",
        "### Next Steps:\n",
        "- We will **focus on semantic metrics** like cosine similarity that focus on meaning rather than exact matches.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTh98-XPhUBm",
        "outputId": "3d273270-ed93-4b2e-bb18-c0451109a5cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertModel were not initialized from the model checkpoint at /content/drive/My Drive/SQuAD_datasets/saved_model/ and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: Name some models that are based on the Transformer architecture\n",
            "Predicted Answer: bert, gpt, and t5\n",
            "Ground Truth: BERT, GPT, and T5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.88, Recall: 0.88, F1 Score: 0.88\n",
            "BLEU Score: 0.08, Levenshtein Score: 0.53\n",
            "ROUGE-1: 1.00, ROUGE-L: 1.00\n",
            "BERTScore F1: 0.94, Cosine Similarity: 1.00\n",
            "Jaccard Similarity: 0.14\n",
            "\n",
            "Question: What mechanism does the Transformer rely on\n",
            "Predicted Answer: self - attention mechanisms\n",
            "Ground Truth: Self-attention mechanisms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 1.00, Recall: 1.00, F1 Score: 1.00\n",
            "BLEU Score: 0.08, Levenshtein Score: 0.89\n",
            "ROUGE-1: 1.00, ROUGE-L: 1.00\n",
            "BERTScore F1: 0.95, Cosine Similarity: 1.00\n",
            "Jaccard Similarity: 0.20\n",
            "\n",
            "Question: Why are Transformers faster than traditional RNNs?\n",
            "Predicted Answer: transformers rely entirely on self - attention mechanisms to capture the relationships between different parts of a sequence\n",
            "Ground Truth: Transformers rely entirely on self-attention mechanisms, which captures the relationship between different parts of a sentence\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.78, Recall: 0.74, F1 Score: 0.76\n",
            "BLEU Score: 0.28, Levenshtein Score: 0.90\n",
            "ROUGE-1: 0.88, ROUGE-L: 0.88\n",
            "BERTScore F1: 0.95, Cosine Similarity: 0.98\n",
            "Jaccard Similarity: 0.36\n",
            "\n",
            "Question: What happens if self-attention mechanism captures the relationship between different parts of a sequence?\n",
            "Predicted Answer: allows transformers to process data in parallel\n",
            "Ground Truth: Transformers can process data in parallel\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.71, Recall: 0.83, F1 Score: 0.77\n",
            "BLEU Score: 0.41, Levenshtein Score: 0.77\n",
            "ROUGE-1: 0.77, ROUGE-L: 0.77\n",
            "BERTScore F1: 0.94, Cosine Similarity: 0.95\n",
            "Jaccard Similarity: 0.44\n",
            "\n",
            "Question: State some applications of Transformers?\n",
            "Predicted Answer: machine translation, text generation, and question answering\n",
            "Ground Truth: Machine translation, text generation, and question answering\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.89, Recall: 0.89, F1 Score: 0.89\n",
            "BLEU Score: 0.81, Levenshtein Score: 0.98\n",
            "ROUGE-1: 1.00, ROUGE-L: 1.00\n",
            "BERTScore F1: 1.00, Cosine Similarity: 1.00\n",
            "Jaccard Similarity: 0.75\n",
            "\n",
            "Question: Who introduced self Attention?\n",
            "Predicted Answer: vaswani et al.\n",
            "Ground Truth: Vaswani et al.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 1.00, Recall: 1.00, F1 Score: 1.00\n",
            "BLEU Score: 0.24, Levenshtein Score: 0.93\n",
            "ROUGE-1: 1.00, ROUGE-L: 1.00\n",
            "BERTScore F1: 1.00, Cosine Similarity: 1.00\n",
            "Jaccard Similarity: 0.50\n",
            "\n",
            "\n",
            "--- Consolidated Metrics ---\n",
            "Precision: 0.88\n",
            "Recall: 0.89\n",
            "F1: 0.88\n",
            "Bleu: 0.32\n",
            "Levenshtein: 0.83\n",
            "Rouge-1: 0.94\n",
            "Rouge-l: 0.94\n",
            "Bertscore f1: 0.96\n",
            "Cosine similarity: 0.99\n",
            "Jaccard similarity: 0.40\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizerFast, BertForQuestionAnswering, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from nltk import edit_distance\n",
        "from rouge_score import rouge_scorer\n",
        "from bert_score import score as bert_score\n",
        "import numpy as np\n",
        "\n",
        "# Load BERT model and tokenizer\n",
        "model_path = 'D:/Rajesh/Rajesh/Personal/AISanDiego/520-NLP/Project/saved_model/'\n",
        "model = BertForQuestionAnswering.from_pretrained(model_path)\n",
        "embedding_model = BertModel.from_pretrained(model_path)  # For embeddings\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_path)\n",
        "\n",
        "# Example context and questions\n",
        "context = (\"Transformers are a type of deep learning model introduced in the paper 'Attention is All You Need' by Vaswani et al. \"\n",
        "           \"in 2017. Unlike traditional recurrent neural networks (RNNs), Transformers rely entirely on self-attention mechanisms \"\n",
        "           \"to capture the relationships between different parts of a sequence. This allows Transformers to process data in parallel, \"\n",
        "           \"making them much faster and more efficient for tasks like natural language processing. Transformers are the foundation for \"\n",
        "           \"many state-of-the-art models, such as BERT, GPT, and T5. They are used in a variety of applications, including machine translation, \"\n",
        "           \"text generation, and question answering.\")\n",
        "\n",
        "questions = [\n",
        "    \"Name some models that are based on the Transformer architecture\",\n",
        "    \"What mechanism does the Transformer rely on\",\n",
        "    \"Why are Transformers faster than traditional RNNs?\",\n",
        "    \"What happens if self-attention mechanism captures the relationship between different parts of a sequence?\",\n",
        "    \"State some applications of Transformers?\",\n",
        "    \"Who introduced self Attention?\"\n",
        "]\n",
        "\n",
        "ground_truths = [\n",
        "    \"BERT, GPT, and T5\",\n",
        "    \"Self-attention mechanisms\",\n",
        "    \"Transformers rely entirely on self-attention mechanisms, which captures the relationship between different parts of a sentence\",\n",
        "    \"Transformers can process data in parallel\",\n",
        "    \"Machine translation, text generation, and question answering\",\n",
        "    \"Vaswani et al.\"\n",
        "]\n",
        "\n",
        "# Function to extract answer from model\n",
        "def answer_question(question, context):\n",
        "    inputs = tokenizer.encode_plus(question, context, return_tensors='pt', truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get the most likely beginning and end of answer\n",
        "    answer_start = torch.argmax(outputs.start_logits)\n",
        "    answer_end = torch.argmax(outputs.end_logits) + 1\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
        "\n",
        "    return answer\n",
        "\n",
        "# Function to compute metrics\n",
        "def compute_metrics(pred_answer, true_answer):\n",
        "    # Tokenize the predicted and true answers\n",
        "    pred_tokens = tokenizer.tokenize(pred_answer.lower())\n",
        "    true_tokens = tokenizer.tokenize(true_answer.lower())\n",
        "\n",
        "    # Token-based Precision, Recall, and F1\n",
        "    common_tokens = set(pred_tokens) & set(true_tokens)\n",
        "    precision = len(common_tokens) / len(pred_tokens) if pred_tokens else 0\n",
        "    recall = len(common_tokens) / len(true_tokens) if true_tokens else 0\n",
        "    f1 = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
        "\n",
        "    # BLEU Score with smoothing\n",
        "    smoothing_fn = SmoothingFunction().method1\n",
        "    bleu = sentence_bleu([true_answer.split()], pred_answer.split(), smoothing_function=smoothing_fn)\n",
        "\n",
        "    # Levenshtein Distance\n",
        "    levenshtein_dist = edit_distance(pred_answer, true_answer)\n",
        "    levenshtein_score = 1 - (levenshtein_dist / max(len(pred_answer), len(true_answer)))\n",
        "\n",
        "    # ROUGE Score\n",
        "    rouge_scorer_inst = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
        "    rouge_scores = rouge_scorer_inst.score(true_answer, pred_answer)\n",
        "\n",
        "    # BERTScore\n",
        "    P, R, F1 = bert_score([pred_answer], [true_answer], lang=\"en\", verbose=False)\n",
        "\n",
        "    # Cosine Similarity using BERT embeddings\n",
        "    pred_emb = np.mean(embedding_model.embeddings.word_embeddings(torch.tensor(tokenizer.convert_tokens_to_ids(pred_tokens))).detach().numpy(), axis=0)\n",
        "    true_emb = np.mean(embedding_model.embeddings.word_embeddings(torch.tensor(tokenizer.convert_tokens_to_ids(true_tokens))).detach().numpy(), axis=0)\n",
        "    cosine_sim = cosine_similarity([pred_emb], [true_emb])[0][0]\n",
        "\n",
        "    # Jaccard Similarity (word overlap)\n",
        "    pred_set = set(pred_answer.split())\n",
        "    true_set = set(true_answer.split())\n",
        "    jaccard_sim = len(pred_set & true_set) / len(pred_set | true_set) if pred_set | true_set else 0.0\n",
        "\n",
        "    return {\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'bleu': bleu,\n",
        "        'levenshtein': levenshtein_score,\n",
        "        'rouge-1': rouge_scores['rouge1'].fmeasure,\n",
        "        'rouge-L': rouge_scores['rougeL'].fmeasure,\n",
        "        'bertscore_f1': F1.mean().item(),\n",
        "        'cosine_similarity': cosine_sim,\n",
        "        'jaccard_similarity': jaccard_sim\n",
        "    }\n",
        "\n",
        "# Evaluate the model on the questions\n",
        "metrics_summary = {\n",
        "    'precision': [],\n",
        "    'recall': [],\n",
        "    'f1': [],\n",
        "    'bleu': [],\n",
        "    'levenshtein': [],\n",
        "    'rouge-1': [],\n",
        "    'rouge-L': [],\n",
        "    'bertscore_f1': [],\n",
        "    'cosine_similarity': [],\n",
        "    'jaccard_similarity': []\n",
        "}\n",
        "\n",
        "for question, truth in zip(questions, ground_truths):\n",
        "    pred_answer = answer_question(question, context)\n",
        "    print(f\"Question: {question}\")\n",
        "    print(f\"Predicted Answer: {pred_answer}\")\n",
        "    print(f\"Ground Truth: {truth}\")\n",
        "\n",
        "    metrics = compute_metrics(pred_answer, truth)\n",
        "\n",
        "    for key in metrics_summary:\n",
        "        metrics_summary[key].append(metrics[key])\n",
        "\n",
        "    # Print individual metrics\n",
        "    print(f\"Precision: {metrics['precision']:.2f}, Recall: {metrics['recall']:.2f}, F1 Score: {metrics['f1']:.2f}\")\n",
        "    print(f\"BLEU Score: {metrics['bleu']:.2f}, Levenshtein Score: {metrics['levenshtein']:.2f}\")\n",
        "    print(f\"ROUGE-1: {metrics['rouge-1']:.2f}, ROUGE-L: {metrics['rouge-L']:.2f}\")\n",
        "    print(f\"BERTScore F1: {metrics['bertscore_f1']:.2f}, Cosine Similarity: {metrics['cosine_similarity']:.2f}\")\n",
        "    print(f\"Jaccard Similarity: {metrics['jaccard_similarity']:.2f}\\n\")\n",
        "\n",
        "# Consolidate metrics\n",
        "print(\"\\n--- Consolidated Metrics ---\")\n",
        "for key, values in metrics_summary.items():\n",
        "    avg_value = sum(values) / len(values)\n",
        "    print(f\"{key.capitalize().replace('_', ' ')}: {avg_value:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here’s an interpretation of the consolidated metrics we obtained for the model:\n",
        "\n",
        "### 1. **Precision: 0.88**\n",
        "   - **Meaning**: Of all the tokens the model predicted in its answers, 88% were correct.\n",
        "   - **Interpretation**: The model is fairly precise in predicting relevant tokens, meaning it is good at predicting correct information without including too much irrelevant content.\n",
        "\n",
        "### 2. **Recall: 0.89**\n",
        "   - **Meaning**: Of all the relevant tokens from the ground truth answers, the model correctly retrieved 89%.\n",
        "   - **Interpretation**: The model does a good job at recalling the necessary details from the ground truth, slightly better than precision, which means it's retrieving most relevant tokens.\n",
        "\n",
        "### 3. **F1 Score: 0.88**\n",
        "   - **Meaning**: This is the harmonic mean of precision and recall, reflecting a balance between the two.\n",
        "   - **Interpretation**: A high F1 score indicates the model performs well overall, balancing between not predicting too much irrelevant information (precision) and still retrieving most of the relevant tokens (recall).\n",
        "\n",
        "### 4. **BLEU Score: 0.32**\n",
        "   - **Meaning**: BLEU (Bilingual Evaluation Understudy) evaluates how closely the predicted answer matches the ground truth, considering n-gram overlaps.\n",
        "   - **Interpretation**: A BLEU score of 0.32 indicates that while the model is capturing some of the n-grams (word sequences), it's not perfectly aligned with the structure of the ground truth. This score tends to be lower when predictions deviate in word choice or order from the expected answer.\n",
        "\n",
        "### 5. **Levenshtein Score: 0.83**\n",
        "   - **Meaning**: The Levenshtein distance measures how many edits (insertions, deletions, or substitutions) are needed to transform the predicted answer into the ground truth. A score of 0.83 indicates an 83% match.\n",
        "   - **Interpretation**: This high score suggests that the predicted answers are quite close to the ground truth in terms of word similarity, with only minor changes needed.\n",
        "\n",
        "### 6. **ROUGE-1: 0.94 & ROUGE-L: 0.94**\n",
        "   - **Meaning**: ROUGE-1 measures the overlap of unigrams (individual words), while ROUGE-L evaluates the longest common subsequence between the prediction and ground truth.\n",
        "   - **Interpretation**: A score of 0.94 for both indicates that the model’s answers contain a significant amount of the same words and sequences as the ground truth, showing strong alignment.\n",
        "\n",
        "### 7. **BERTScore F1: 0.96**\n",
        "   - **Meaning**: BERTScore evaluates the semantic similarity between the predicted and true answers using embeddings. A score of 0.96 indicates very high semantic similarity.\n",
        "   - **Interpretation**: The model’s predictions are highly aligned semantically with the ground truth, even if they may not match perfectly word-for-word.\n",
        "\n",
        "### 8. **Cosine Similarity: 0.99**\n",
        "   - **Meaning**: Cosine similarity compares the vector embeddings of the predicted and true answers. A value of 0.99 indicates that the vectors are almost identical.\n",
        "   - **Interpretation**: The predictions are nearly identical to the true answers in terms of overall meaning and representation in embedding space.\n",
        "\n",
        "### 9. **Jaccard Similarity: 0.40**\n",
        "   - **Meaning**: Jaccard similarity measures the overlap of unique words between the predicted and ground truth answers. A score of 0.40 indicates only a moderate amount of overlap in word choice.\n",
        "   - **Interpretation**: The model's predicted answers contain only 40% of the same unique words as the ground truth. This suggests that while the answers are semantically correct (based on BERTScore and cosine similarity), the exact word usage differs more significantly.\n",
        "\n",
        "### **Overall Interpretation**:\n",
        "The model performs very well on semantic metrics like **BERTScore** and **Cosine Similarity**, indicating that it captures the meaning of the answers quite well. The high **ROUGE** scores also show strong word overlap with the ground truth. However, the **BLEU** and **Jaccard** scores are somewhat lower, suggesting that the exact wording or phrasing of the model’s responses may deviate from the expected ground truth, even though the meaning remains highly accurate.\n",
        "\n",
        "In summary, while the model might not always match the exact wording of the expected answers, it is highly effective in capturing the underlying meaning."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04171bc0fc2a4197a5a4c42eb2fadecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6553701497f84901b39ebce9002b7dd6",
            "placeholder": "​",
            "style": "IPY_MODEL_b51dd88b060c421e9026e5df5def7958",
            "value": "tokenizer.json: 100%"
          }
        },
        "06f11c0705eb4f2ea8743dc047eeb99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a633128f5064f25bd73fca1ba5af708",
            "placeholder": "​",
            "style": "IPY_MODEL_824698aa40d241beb898fb0bc5912831",
            "value": "config.json: 100%"
          }
        },
        "0ee67edd1963406e8dc8d7203f923cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d3751db4de044b8ae738c988b13dcdb",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_400cb2c636f549fb946c1ed859cfbeef",
            "value": 231508
          }
        },
        "110779c2ebd542788cf2ef7a729505c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1167ea73ef1142698e03e0822324e0cd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19366ac578444aeaa486f6c5dca5dd33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23f84ca6af19443e82332b9efcdcfae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06f11c0705eb4f2ea8743dc047eeb99a",
              "IPY_MODEL_48949b3a9fa6432e84c91bc477203789",
              "IPY_MODEL_d8c86f36586941a8a705080111a97764"
            ],
            "layout": "IPY_MODEL_c3593d1c75b04e269a65fd0220801fbb"
          }
        },
        "262cea56513e49c686e98b1bb6a1d2cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d4696dee5ba40b5aad3d63e6f69cb75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3525dc6010db4c98bc844bcb01ce4178": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39638759e0904abcbf2785ef9a54246e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "400cb2c636f549fb946c1ed859cfbeef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4576b10859b34fb7bcc3ccaa03ea2787": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48949b3a9fa6432e84c91bc477203789": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d4696dee5ba40b5aad3d63e6f69cb75",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80df567ed815462593e526ae31575dac",
            "value": 570
          }
        },
        "490fcd8380034753a4252edc6dce243c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bcaf8d13cd94add9f35cef837c12f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b025b9eeda84c3b9d41121730143e2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc09156994394512a87cbe5e0f93a9ed",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f837c0ab11a3481d902f513a0b5cf368",
            "value": 466062
          }
        },
        "5d3751db4de044b8ae738c988b13dcdb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f8dc1e2d56040808bed19396fed8835": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b976f48c90484bf1969b842efac0ccaa",
            "placeholder": "​",
            "style": "IPY_MODEL_eb48eb51fac24903aa71bea49d39b396",
            "value": "vocab.txt: 100%"
          }
        },
        "606fbb0b86394094a3a2c4a229f554bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19366ac578444aeaa486f6c5dca5dd33",
            "placeholder": "​",
            "style": "IPY_MODEL_e3b2b824fc9b4891b05d87206cff3c92",
            "value": " 466k/466k [00:00&lt;00:00, 2.42MB/s]"
          }
        },
        "6553701497f84901b39ebce9002b7dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a633128f5064f25bd73fca1ba5af708": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78fcba1e262d4325a254aa2137258c4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d54124d6b6d4d9f8721aae6f87ede96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39638759e0904abcbf2785ef9a54246e",
            "placeholder": "​",
            "style": "IPY_MODEL_8f83a99a2cd94641b0a8ff827e016db0",
            "value": " 232k/232k [00:00&lt;00:00, 1.72MB/s]"
          }
        },
        "80df567ed815462593e526ae31575dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "824698aa40d241beb898fb0bc5912831": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f83a99a2cd94641b0a8ff827e016db0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "919aa70af4454e878072f6588369dcb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3f41fccdda3488cb8423def393e1a59",
              "IPY_MODEL_9c1f24d09154400a9392dc4a8e685f03",
              "IPY_MODEL_93ba3485d4114cea8c1bc27f3289b034"
            ],
            "layout": "IPY_MODEL_78fcba1e262d4325a254aa2137258c4e"
          }
        },
        "93ba3485d4114cea8c1bc27f3289b034": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_110779c2ebd542788cf2ef7a729505c3",
            "placeholder": "​",
            "style": "IPY_MODEL_bd60145f294640f58b3c58d88a5286ba",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.59kB/s]"
          }
        },
        "9c1f24d09154400a9392dc4a8e685f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1167ea73ef1142698e03e0822324e0cd",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bcaf8d13cd94add9f35cef837c12f61",
            "value": 48
          }
        },
        "b0997028e678479ba55c63d905749683": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f8dc1e2d56040808bed19396fed8835",
              "IPY_MODEL_0ee67edd1963406e8dc8d7203f923cfe",
              "IPY_MODEL_7d54124d6b6d4d9f8721aae6f87ede96"
            ],
            "layout": "IPY_MODEL_3525dc6010db4c98bc844bcb01ce4178"
          }
        },
        "b3f41fccdda3488cb8423def393e1a59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db2f96f1367748958d99557933008884",
            "placeholder": "​",
            "style": "IPY_MODEL_490fcd8380034753a4252edc6dce243c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b51dd88b060c421e9026e5df5def7958": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b976f48c90484bf1969b842efac0ccaa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd60145f294640f58b3c58d88a5286ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3593d1c75b04e269a65fd0220801fbb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc09156994394512a87cbe5e0f93a9ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8c86f36586941a8a705080111a97764": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e36dfeb046d64556ba9125784fffe92a",
            "placeholder": "​",
            "style": "IPY_MODEL_4576b10859b34fb7bcc3ccaa03ea2787",
            "value": " 570/570 [00:00&lt;00:00, 49.8kB/s]"
          }
        },
        "db2f96f1367748958d99557933008884": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e36dfeb046d64556ba9125784fffe92a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3b2b824fc9b4891b05d87206cff3c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb48eb51fac24903aa71bea49d39b396": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f837c0ab11a3481d902f513a0b5cf368": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f943ef6eb17245b0b2b1f1e5d65452e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04171bc0fc2a4197a5a4c42eb2fadecd",
              "IPY_MODEL_5b025b9eeda84c3b9d41121730143e2a",
              "IPY_MODEL_606fbb0b86394094a3a2c4a229f554bb"
            ],
            "layout": "IPY_MODEL_262cea56513e49c686e98b1bb6a1d2cc"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
